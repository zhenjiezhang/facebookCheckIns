{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "_train_=pd.read_csv('../input/train.csv')\n",
    "places=_train_['place_id'].unique()\n",
    "\n",
    "_train_.sort(['time'], inplace=True)\n",
    "trainRatio=0.7\n",
    "train=_train_[:int(len(_train_)*trainRatio)]\n",
    "train=train[train['accuracy']<1000]\n",
    "\n",
    "placeCounts=train['place_id'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "valid=_train_[int(len(_train_)*trainRatio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureFactory(dataFrame):\n",
    "    dataFrame.loc[:,'xTimeY']=dataFrame.loc[:, 'x']*dataFrame.loc[:, 'y']\n",
    "    dataFrame.loc[:,'xDivY']=dataFrame.loc[:, 'x'].div(dataFrame.loc[:, 'y'])\n",
    "\n",
    "    dataFrame.loc[:,'accuracy']=np.log10(dataFrame.loc[:, 'accuracy'])\n",
    "    \n",
    "    dataFrame.loc[:,'day']=dataFrame.loc[:, 'time'].div(1440).map(int)\n",
    "    dataFrame.loc[:,'weekday']=dataFrame.loc[:,'day']%7\n",
    "    dataFrame.loc[:,'weekdayShifted']=(dataFrame.loc[:,'weekday']+3)%7\n",
    "    dataFrame.loc[:,'dayInMonth']=dataFrame.loc[:, 'day']%(30)\n",
    "    dataFrame.loc[:,'year']=dataFrame.loc[:,'day'].div(365).map(int)\n",
    "    \n",
    "    dataFrame.loc[:,'month']=(dataFrame.loc[:,'day']%365).div(30).map(int)\n",
    "    dataFrame.loc[:,'hour']=dataFrame.loc[:,'time'].div(60).map(int)\n",
    "    dataFrame.loc[:, 'hourInDay']=dataFrame.loc[:,'hour']%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted1']=(dataFrame.loc[:,'hourInDay']+6)%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted2']=(dataFrame.loc[:,'hourInDay']+12)%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted3']=(dataFrame.loc[:,'hourInDay']+18)%24\n",
    "\n",
    " \n",
    "    dataFrame.loc[:, 'originalIndex']=xrange(len(dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureFactory(train)\n",
    "featureFactory(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('../input/test.csv')\n",
    "featureFactory(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xMean</th>\n",
       "      <th>xStd</th>\n",
       "      <th>yMean</th>\n",
       "      <th>yStd</th>\n",
       "      <th>hourInDayMean</th>\n",
       "      <th>hourInDayStd</th>\n",
       "      <th>monthMean</th>\n",
       "      <th>monthStd</th>\n",
       "      <th>dayMean</th>\n",
       "      <th>dayStd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000015801</th>\n",
       "      <td>2.690521</td>\n",
       "      <td>0.167190</td>\n",
       "      <td>5.550822</td>\n",
       "      <td>0.014536</td>\n",
       "      <td>16.277778</td>\n",
       "      <td>5.544245</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>2.995008</td>\n",
       "      <td>128.638889</td>\n",
       "      <td>103.437306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000017288</th>\n",
       "      <td>7.331718</td>\n",
       "      <td>0.338637</td>\n",
       "      <td>4.346353</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>12.734940</td>\n",
       "      <td>4.123355</td>\n",
       "      <td>4.915663</td>\n",
       "      <td>3.390103</td>\n",
       "      <td>187.385542</td>\n",
       "      <td>111.164439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000025138</th>\n",
       "      <td>0.987195</td>\n",
       "      <td>0.043501</td>\n",
       "      <td>5.570373</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>12.624130</td>\n",
       "      <td>3.614283</td>\n",
       "      <td>5.624130</td>\n",
       "      <td>3.779722</td>\n",
       "      <td>231.658933</td>\n",
       "      <td>111.817801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000052096</th>\n",
       "      <td>2.849199</td>\n",
       "      <td>0.446559</td>\n",
       "      <td>5.833482</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>9.787356</td>\n",
       "      <td>3.360055</td>\n",
       "      <td>4.525862</td>\n",
       "      <td>3.551782</td>\n",
       "      <td>183.886494</td>\n",
       "      <td>118.262177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000063498</th>\n",
       "      <td>3.867737</td>\n",
       "      <td>1.084438</td>\n",
       "      <td>7.547868</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>16.684211</td>\n",
       "      <td>2.688507</td>\n",
       "      <td>7.052632</td>\n",
       "      <td>3.487656</td>\n",
       "      <td>266.210526</td>\n",
       "      <td>93.450866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xMean      xStd     yMean      yStd  hourInDayMean  \\\n",
       "place_id                                                            \n",
       "1000015801  2.690521  0.167190  5.550822  0.014536      16.277778   \n",
       "1000017288  7.331718  0.338637  4.346353  0.010564      12.734940   \n",
       "1000025138  0.987195  0.043501  5.570373  0.010376      12.624130   \n",
       "1000052096  2.849199  0.446559  5.833482  0.011319       9.787356   \n",
       "1000063498  3.867737  1.084438  7.547868  0.022191      16.684211   \n",
       "\n",
       "            hourInDayStd  monthMean  monthStd     dayMean      dayStd  \n",
       "place_id                                                               \n",
       "1000015801      5.544245   3.291667  2.995008  128.638889  103.437306  \n",
       "1000017288      4.123355   4.915663  3.390103  187.385542  111.164439  \n",
       "1000025138      3.614283   5.624130  3.779722  231.658933  111.817801  \n",
       "1000052096      3.360055   4.525862  3.551782  183.886494  118.262177  \n",
       "1000063498      2.688507   7.052632  3.487656  266.210526   93.450866  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.348020077\n"
     ]
    }
   ],
   "source": [
    "g=train.groupby('place_id')\n",
    "places=pd.DataFrame()\n",
    "places['xMean']=g['x'].mean()\n",
    "places['xStd']=g['x'].std()\n",
    "\n",
    "places['yMean']=g['y'].mean()\n",
    "places['yStd']=g['y'].std()\n",
    "\n",
    "places['hourInDayMean']=g['hourInDay'].mean()\n",
    "places['hourInDayStd']=g['hourInDay'].std()\n",
    "\n",
    "places['monthMean']=g['month'].mean()\n",
    "places['monthStd']=g['month'].std()\n",
    "\n",
    "places['dayMean']=g['day'].mean()\n",
    "places['dayStd']=g['day'].std()\n",
    "\n",
    "places.head()\n",
    "\n",
    "sTime=time.time()\n",
    "\n",
    "train=train[(abs(train['y']-places.loc[train['place_id'], 'yMean'].values)<5*places.loc[train['place_id'], 'yStd'].values)\\\n",
    "         & (abs(train['x']-places.loc[train['place_id'], 'xMean'].values)<5*places.loc[train['place_id'], 'xStd'].values)\\\n",
    "           \n",
    "           ]\n",
    "\n",
    "print time.time()-sTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 0 2 10 10\n"
     ]
    }
   ],
   "source": [
    "nXRegions=50\n",
    "nYRegions=50\n",
    "xMin=0\n",
    "xMax=2\n",
    "yMin=0\n",
    "yMax=2\n",
    "nXRegions=nXRegions*int(xMax-xMin)/10\n",
    "nYRegions=nYRegions*int(yMax-yMin)/10\n",
    "# train=train[(train['x']<xMax) & (train['x']>=xMin) & (train['y']<yMax) & (train['y']>=yMin)]\n",
    "# valid=valid[(valid['x']<xMax) & (valid['x']>=xMin) & (valid['y']<yMax) & (valid['y']>=yMin)]\n",
    "\n",
    "print xMin, xMax, yMin, yMax, nXRegions, nYRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def regionalForestPred(pred, classes, regionalPoints, data):\n",
    "\n",
    "    \n",
    "#     prob=[sorted(zip(p, classes))[-3:][::-1] for p in pred]\n",
    "    \n",
    "    \n",
    "#     regionalPred=[]\n",
    "#     for i in xrange(len(data)):\n",
    "#         sampleY=data['y'].iloc[i]\n",
    "#         sampleX=data['x'].iloc[i]\n",
    "#         sampleDay=data['day'].iloc[i]\n",
    "\n",
    "#         filteredPlaces=filter(lambda x: \\\n",
    "#                               sampleY<=yMaxMap[x[1]]+yAllowance and sampleY>=yMinMap[x[1]]-yAllowance and \\\n",
    "#                               sampleX<=xMaxMap[x[1]] and sampleX>=xMinMap[x[1]] and \\\n",
    "#                               sampleDay<=dayMaxMap[x[1]] and sampleDay>=dayMinMap[x[1]], prob[i])\n",
    "#         if filteredPlaces:\n",
    "#             filteredPlaces=map(lambda x: [x[0]*regionalPoints, x[1]], filteredPlaces)\n",
    "#         regionalPred.append(filteredPlaces)\n",
    "#     return regionalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test(modelSerialization=False, resultSerialization=False, model='rf', predictSet=valid, th=0, xMargin=0.05, yMargin=0.025):\n",
    "    \n",
    "    if modelSerialization or resultSerialization:\n",
    "        base='./'\n",
    "        folderName=model+'-'+time.strftime('%c')\n",
    "        folderPath=base+folderName+'/'\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.makedirs(folderPath)\n",
    "            \n",
    "    \n",
    "#     f=['x','y','xTimeY','xDivY', 'accuracy', 'day', 'weekday', 'hourInDay','hourInDayShifted2', 'month', 'year']\n",
    "    f=['x','y', 'accuracy', 'day','weekday', 'hourInDay','hourInDayShifted2', 'month', 'year']\n",
    "        \n",
    "    count=0\n",
    "    accuracies=[]\n",
    "    FBscores=[]\n",
    "    \n",
    "    startTime=time.time()\n",
    "    trainingTimes=[]\n",
    "    predictionTimes=[]\n",
    "    \n",
    "    testNum=0\n",
    "\n",
    "    roundNum=5\n",
    "\n",
    "    for xNum, yNum in ((xn, yn) for xn in xrange(nXRegions) for yn in xrange(nYRegions)):\n",
    "\n",
    "        xStep=round(1.0*(xMax-xMin)/nXRegions,roundNum)\n",
    "        xStart=round(xMin+xNum*xStep,roundNum)\n",
    "        xEnd=round(xStart+xStep,roundNum)\n",
    "\n",
    "        yStep=round(1.0*(yMax-yMin)/nYRegions,roundNum)\n",
    "        yStart=round(yMin+yNum*yStep,roundNum)\n",
    "        yEnd=round(yStart+yStep,roundNum)\n",
    "        \n",
    "#         regionalTrain=train[(train['x']<xEnd) & (train['x']>=xStart) & (train['y']<yEnd) & (train['y']>=yStart)]\n",
    "\n",
    "        regionalTrain=train[(train['x']<xEnd+xMargin) & (train['x']>=xStart-xMargin) & (train['y']<yEnd+yMargin) & (train['y']>=yStart-yMargin)]\n",
    "#         print xStart, xEnd, yStart, yEnd, len(regionalTrain)\n",
    "\n",
    "        \n",
    "            \n",
    "#         regionalTrain['sampleWeight']=\n",
    "\n",
    "\n",
    "        placesCounts=regionalTrain['place_id'].value_counts()\n",
    "        regionalTrain=regionalTrain[(placeCounts[regionalTrain['place_id'].values]>th).values]\n",
    "        \n",
    "        tail=len(regionalTrain)/6\n",
    "        latest=regionalTrain.sort_values(by=['time'])[:tail]\n",
    "        regionalTrain=regionalTrain.append(latest)\n",
    "        \n",
    "        \n",
    "        addition=regionalTrain[regionalTrain['hourInDay']<=4]\n",
    "        addition['hourInDay']=addition['hourInDay']+24\n",
    "        regionalTrain=regionalTrain.append(addition)\n",
    "        \n",
    "        addition=regionalTrain[regionalTrain['hourInDay']>=20]\n",
    "        addition['hourInDay']=addition['hourInDay']-24\n",
    "        regionalTrain=regionalTrain.append(addition)\n",
    "\n",
    "\n",
    "        \n",
    "        if len(regionalTrain):\n",
    "#             regionalPredictSet=predictSet[(predictSet['x']<xEnd-margin) & (predictSet['x']>=xStart+margin) & (predictSet['y']<yEnd-margin) & (predictSet['y']>=yStart+margin)]\n",
    "            regionalPredictSet=predictSet[(predictSet['x']<xEnd) & (predictSet['x']>=xStart) & (predictSet['y']<yEnd) & (predictSet['y']>=yStart)]\n",
    "\n",
    "            testNum+=len(regionalPredictSet)\n",
    "\n",
    "            if model=='knn':\n",
    "                fWeights={'x': 500, 'y': 1000, 'accuracy':0, 'day': 0,'dayInMonth': 0, 'weekday': 3,\\\n",
    "                          'hourInDay': 4, 'hourInDayShifted2': 0, 'month': 2, 'year': 10}\n",
    "                for ft in f:\n",
    "                    regionalTrain[ft]=regionalTrain[ft].values*fWeights[ft]\n",
    "                    regionalPredictSet[ft]=regionalPredictSet[ft].values*fWeights[ft]\n",
    "                \n",
    "            else:\n",
    "                fMean=regionalTrain[f].mean()\n",
    "                fStd=regionalTrain[f].std()\n",
    "\n",
    "                for ft in f:       \n",
    "                    regionalTrain[ft]=(regionalTrain[ft].values-fMean[ft])/(fStd[ft])\n",
    "                    regionalPredictSet[ft]=(regionalPredictSet[ft].values-fMean[ft])/(fStd[ft])\n",
    "#                 print regionalTrain['x'].describe()\n",
    "\n",
    "      \n",
    "            le=LabelEncoder()\n",
    "            regionalTrain['le']=le.fit_transform(regionalTrain['place_id'].values)\n",
    "\n",
    "#             s_w=1**(15-regionalTrain['day'].values/30.0)\n",
    "            \n",
    "            trainingStartTime=time.time()\n",
    "            if model=='rf':\n",
    "                s_w_rf=3**(-regionalTrain['day'].values)\n",
    "#                 s_w_rf=1.65-regionalTrain['day'].values\n",
    "    #             clf=RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=None).fit(regionalTrain[f], regionalTrain['le'])   \n",
    "            \n",
    "                clf=RandomForestClassifier(n_jobs=-1, n_estimators=150, random_state=0, min_samples_split=4).fit(regionalTrain[f], regionalTrain['le'], sample_weight=s_w_rf)  \n",
    "\n",
    "            if model=='xgb':\n",
    "                clf=XGBClassifier(learning_rate=0.02, n_estimators=220, objective='multi:softprob', max_depth=3, seed=0).fit(regionalTrain[f], regionalTrain['le'])\n",
    "            \n",
    "            \n",
    "            if model=='knn':\n",
    "                clf=KNeighborsClassifier(n_neighbors=25, weights='distance',metric='manhattan', n_jobs=-1).fit(regionalTrain[f], regionalTrain['le'])\n",
    "         \n",
    "            trainingTimes.append(time.time()-trainingStartTime)\n",
    "            \n",
    "            \n",
    "            if modelSerialization:\n",
    "                modelFileName='{:04d}-{}-{}-{}-{}.clf'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                modelFilePath=folderPath+modelFileName\n",
    "                with open(modelFilePath, 'ab+') as fo:\n",
    "                    pickle.dump(clf, fo, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "            predictionStartTime=time.time()\n",
    "            prob=clf.predict_proba(regionalPredictSet[f])\n",
    "            predictionTimes.append(time.time()-predictionStartTime)\n",
    "            \n",
    "            pred=[sorted(zip(p, clf.classes_))[-3:][::-1] for p in prob]\n",
    "            prediction=le.inverse_transform([zip(*p)[1] for p in pred])\n",
    "            confidence=[zip(*p)[0] for p in pred]\n",
    "            \n",
    "            \n",
    "                \n",
    "            fbscoreForSerialization=-1\n",
    "            if 'place_id' in predictSet.columns:\n",
    "                regionalAccuracy=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                regionalConfidence=[sum(z)/len(regionalPredictSet) for z in zip(*confidence)]\n",
    "                regionalConfidence3=sum(regionalConfidence)\n",
    "\n",
    "                fbAccuracy=0\n",
    "                fbAccuracy+=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][:1] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/2*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][1:2] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/3*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][2:3] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                FBscores.append(fbAccuracy)\n",
    "                print 'region {}: {},{} accuracy: {},  fbAccu: {}, confidence: {}:'.format(count, xNum, yNum, regionalAccuracy, fbAccuracy, regionalConfidence3)\n",
    "                accuracies.append(regionalAccuracy)\n",
    "                if resultSerialization:\n",
    "                    fbscoreForSerialization=fbAccuracy\n",
    "                \n",
    "            if resultSerialization:\n",
    "                resultFileName='{:04d}-{}-{}-{}-{}.rst'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                resultFilePath=folderPath+resultFileName\n",
    "                predColumns=zip(*prediction)\n",
    "                confColumns=zip(*confidence)\n",
    "\n",
    "                \n",
    "                if len(predColumns[2])!=len(prediction):\n",
    "                    print 'missing values',count, len(predColumns[0])\n",
    "                \n",
    "                results=pd.DataFrame({'originalIndex': regionalPredictSet['originalIndex'].tolist(),\\\n",
    "                                      'x':regionalPredictSet['x'].tolist(), 'y':regionalPredictSet['y'].tolist(), \\\n",
    "                                      'accuracy':regionalPredictSet['accuracy'].tolist(), 'pred0':predColumns[0], \\\n",
    "                                      'pred1':predColumns[1], 'pred2':predColumns[2], 'conf0': confColumns[0], \\\n",
    "                                      'conf1': confColumns[1], 'conf2': confColumns[2], 'regionalFBScore': [fbscoreForSerialization]*len(regionalPredictSet)})\n",
    "\n",
    "                results.to_csv(resultFilePath)\n",
    "\n",
    "\n",
    "\n",
    "        count+=1\n",
    "        if count%10==0:\n",
    "\n",
    "            print '{} : total time {} s.'.format(count, time.time()-startTime)\n",
    "            print 'Average training Time: ', sum(trainingTimes)/len(trainingTimes)\n",
    "            print 'Average prediction Time: ', sum(predictionTimes)/len(predictionTimes)\n",
    "            print 'Average FB Score', np.mean(FBscores)\n",
    "            print \n",
    "            \n",
    "            startTime=time.time()\n",
    "            trainingTimes=[]\n",
    "            predictionTimes=[]\n",
    "\n",
    "\n",
    "    print \n",
    "    print np.mean(accuracies)\n",
    "    print np.var(accuracies)\n",
    "    print\n",
    "    print np.mean(FBscores)\n",
    "    print testNum\n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test(modelSerialization=False, model='xgb', resultSerialization=False, predictSet=valid, th=3, xMargin=0.06, yMargin=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeSubmission(resultFolder):\n",
    "    results=[]\n",
    "    for f in os.listdir(resultFolder):\n",
    "        if f.endswith('.rst'):\n",
    "            fi=resultFolder+'/'+f\n",
    "            results.append(pd.read_csv(fi))\n",
    "    results=pd.concat(results)\n",
    "        \n",
    "    results.sort(['originalIndex'], inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('../submissions/xgb-0.03-50Trees/')\n",
    "predictions=results[['pred0','pred1','pred2']]\n",
    "submit=pd.DataFrame()\n",
    "# submit.loc[:,'row_id']=np.arange(len(predictions))\n",
    "submit.loc[:,'place_id']=predictions[['pred0', 'pred1', 'pred2']].apply(lambda x: ' '.join([str(nx) for nx in x]), axis=1)\n",
    "submit.loc[:,'row_id']=np.arange(len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit=submit[['row_id','place_id' ]]\n",
    "submit.set_index('row_id', inplace=True)\n",
    "submit.to_csv('../submissions/xgb0.03_50Trees.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p300=pd.read_csv('../submissions/rf300Trees10_250.csv').head()\n",
    "p50=pd.read_csv('../submissions/rf50Trees10_250.csv').head()\n",
    "p300\n",
    "p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others=pd.read_csv('../submissions/rf_submission_2016-06-03-19-57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('rf-Tue Jun 14 18:18:14 2016')\n",
    "predictions=results[['pred0','pred1','pred2']].values\n",
    "\n",
    "realXMin=0\n",
    "realXMax=10.1\n",
    "realYMin=0\n",
    "realYMax=10.1\n",
    "\n",
    "real=_train_[int(len(_train_)*trainRatio):]\n",
    "\n",
    "real=real[(real['x']<realXMax) & (real['x']>=realXMin) & (real['y']<realYMax) & (real['y']>=realYMin)]\n",
    "real=real[['place_id']]\n",
    "\n",
    "print len(real)\n",
    "print len(predictions)\n",
    "\n",
    "# print len(predictions), len(real), results['originalIndex'].value_counts()\n",
    "\n",
    "totalHit=sum([real['place_id'].iloc[i] in predictions[i] for i in xrange(len(predictions))])\n",
    "score=0\n",
    "score+=1.0*sum([real['place_id'].iloc[i] in predictions[i][:1] for i in xrange(len(predictions))])\n",
    "score+=1.0/2*sum([real['place_id'].iloc[i] in predictions[i][1:2] for i in xrange(len(predictions))])\n",
    "score+=1.0/3*sum([real['place_id'].iloc[i] in predictions[i][2:3] for i in xrange(len(predictions))])\n",
    "\n",
    "print 1.0*totalHit/len(predictions)\n",
    "print score/len(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real.head()\n",
    "\n",
    "results[results['originalIndex']==934546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=pd.read_csv('rf-Sun Jun 12 12:17:04 2016/0000-0.0-1.0-0.0-0.04.rst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
