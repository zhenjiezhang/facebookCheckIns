{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "_train_=pd.read_csv('../input/train.csv')\n",
    "places=_train_['place_id'].unique()\n",
    "\n",
    "_train_.sort(['time'], inplace=True)\n",
    "trainRatio=0.7\n",
    "train=_train_[:int(len(_train_)*trainRatio)]\n",
    "train=train[train['accuracy']<1000]\n",
    "\n",
    "placeCounts=train['place_id'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "valid=_train_[int(len(_train_)*trainRatio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureFactory(dataFrame):\n",
    "    dataFrame.loc[:,'xTimeY']=dataFrame.loc[:, 'x']*dataFrame.loc[:, 'y']\n",
    "    dataFrame.loc[:,'xDivY']=dataFrame.loc[:, 'x'].div(dataFrame.loc[:, 'y'])\n",
    "\n",
    "\n",
    "    \n",
    "    dataFrame.loc[:,'day']=dataFrame.loc[:, 'time'].div(1440).map(int)\n",
    "    dataFrame.loc[:,'weekday']=dataFrame.loc[:,'day']%7\n",
    "    dataFrame.loc[:,'weekdayShifted']=(dataFrame.loc[:,'weekday']+3)%7\n",
    "    dataFrame.loc[:,'dayInMonth']=dataFrame.loc[:, 'day']%(30)\n",
    "    dataFrame.loc[:,'year']=dataFrame.loc[:,'day'].div(365).map(int)\n",
    "    \n",
    "    dataFrame.loc[:,'month']=(dataFrame.loc[:,'day']%365).div(30).map(int)\n",
    "    dataFrame.loc[:,'hour']=dataFrame.loc[:,'time'].div(60).map(int)\n",
    "    dataFrame.loc[:, 'hourInDay']=dataFrame.loc[:,'hour']%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted1']=(dataFrame.loc[:,'hourInDay']+6)%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted2']=(dataFrame.loc[:,'hourInDay']+12)%24\n",
    "    dataFrame.loc[:, 'hourInDayShifted3']=(dataFrame.loc[:,'hourInDay']+18)%24\n",
    "\n",
    " \n",
    "    dataFrame.loc[:, 'originalIndex']=xrange(len(dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "featureFactory(train)\n",
    "featureFactory(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('../input/test.csv')\n",
    "featureFactory(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xMean</th>\n",
       "      <th>xStd</th>\n",
       "      <th>yMean</th>\n",
       "      <th>yStd</th>\n",
       "      <th>hourInDayMean</th>\n",
       "      <th>hourInDayStd</th>\n",
       "      <th>monthMean</th>\n",
       "      <th>monthStd</th>\n",
       "      <th>dayMean</th>\n",
       "      <th>dayStd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000015801</th>\n",
       "      <td>2.690521</td>\n",
       "      <td>0.167190</td>\n",
       "      <td>5.550822</td>\n",
       "      <td>0.014536</td>\n",
       "      <td>16.277778</td>\n",
       "      <td>5.544245</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>2.995008</td>\n",
       "      <td>128.638889</td>\n",
       "      <td>103.437306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000017288</th>\n",
       "      <td>7.331718</td>\n",
       "      <td>0.338637</td>\n",
       "      <td>4.346353</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>12.734940</td>\n",
       "      <td>4.123355</td>\n",
       "      <td>4.915663</td>\n",
       "      <td>3.390103</td>\n",
       "      <td>187.385542</td>\n",
       "      <td>111.164439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000025138</th>\n",
       "      <td>0.987195</td>\n",
       "      <td>0.043501</td>\n",
       "      <td>5.570373</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>12.624130</td>\n",
       "      <td>3.614283</td>\n",
       "      <td>5.624130</td>\n",
       "      <td>3.779722</td>\n",
       "      <td>231.658933</td>\n",
       "      <td>111.817801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000052096</th>\n",
       "      <td>2.849199</td>\n",
       "      <td>0.446559</td>\n",
       "      <td>5.833482</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>9.787356</td>\n",
       "      <td>3.360055</td>\n",
       "      <td>4.525862</td>\n",
       "      <td>3.551782</td>\n",
       "      <td>183.886494</td>\n",
       "      <td>118.262177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000063498</th>\n",
       "      <td>3.867737</td>\n",
       "      <td>1.084438</td>\n",
       "      <td>7.547868</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>16.684211</td>\n",
       "      <td>2.688507</td>\n",
       "      <td>7.052632</td>\n",
       "      <td>3.487656</td>\n",
       "      <td>266.210526</td>\n",
       "      <td>93.450866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xMean      xStd     yMean      yStd  hourInDayMean  \\\n",
       "place_id                                                            \n",
       "1000015801  2.690521  0.167190  5.550822  0.014536      16.277778   \n",
       "1000017288  7.331718  0.338637  4.346353  0.010564      12.734940   \n",
       "1000025138  0.987195  0.043501  5.570373  0.010376      12.624130   \n",
       "1000052096  2.849199  0.446559  5.833482  0.011319       9.787356   \n",
       "1000063498  3.867737  1.084438  7.547868  0.022191      16.684211   \n",
       "\n",
       "            hourInDayStd  monthMean  monthStd     dayMean      dayStd  \n",
       "place_id                                                               \n",
       "1000015801      5.544245   3.291667  2.995008  128.638889  103.437306  \n",
       "1000017288      4.123355   4.915663  3.390103  187.385542  111.164439  \n",
       "1000025138      3.614283   5.624130  3.779722  231.658933  111.817801  \n",
       "1000052096      3.360055   4.525862  3.551782  183.886494  118.262177  \n",
       "1000063498      2.688507   7.052632  3.487656  266.210526   93.450866  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.634013891\n"
     ]
    }
   ],
   "source": [
    "g=train.groupby('place_id')\n",
    "places=pd.DataFrame()\n",
    "places['xMean']=g['x'].mean()\n",
    "places['xStd']=g['x'].std()\n",
    "\n",
    "places['yMean']=g['y'].mean()\n",
    "places['yStd']=g['y'].std()\n",
    "\n",
    "places['hourInDayMean']=g['hourInDay'].mean()\n",
    "places['hourInDayStd']=g['hourInDay'].std()\n",
    "\n",
    "places['monthMean']=g['month'].mean()\n",
    "places['monthStd']=g['month'].std()\n",
    "\n",
    "places['dayMean']=g['day'].mean()\n",
    "places['dayStd']=g['day'].std()\n",
    "\n",
    "places.head()\n",
    "\n",
    "sTime=time.time()\n",
    "\n",
    "train=train[(abs(train['y']-places.loc[train['place_id'], 'yMean'].values)<5*places.loc[train['place_id'], 'yStd'].values)\\\n",
    "         & (abs(train['x']-places.loc[train['place_id'], 'xMean'].values)<5*places.loc[train['place_id'], 'xStd'].values)\\\n",
    "           \n",
    "           ]\n",
    "\n",
    "print time.time()-sTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 0 2 4 8\n"
     ]
    }
   ],
   "source": [
    "nXRegions=20\n",
    "nYRegions=40\n",
    "xMin=0\n",
    "xMax=2\n",
    "yMin=0\n",
    "yMax=2\n",
    "nXRegions=nXRegions*int(xMax-xMin)/10\n",
    "nYRegions=nYRegions*int(yMax-yMin)/10\n",
    "# train=train[(train['x']<xMax) & (train['x']>=xMin) & (train['y']<yMax) & (train['y']>=yMin)]\n",
    "# valid=valid[(valid['x']<xMax) & (valid['x']>=xMin) & (valid['y']<yMax) & (valid['y']>=yMin)]\n",
    "\n",
    "print xMin, xMax, yMin, yMax, nXRegions, nYRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def regionalForestPred(pred, classes, regionalPoints, data):\n",
    "\n",
    "    \n",
    "#     prob=[sorted(zip(p, classes))[-3:][::-1] for p in pred]\n",
    "    \n",
    "    \n",
    "#     regionalPred=[]\n",
    "#     for i in xrange(len(data)):\n",
    "#         sampleY=data['y'].iloc[i]\n",
    "#         sampleX=data['x'].iloc[i]\n",
    "#         sampleDay=data['day'].iloc[i]\n",
    "\n",
    "#         filteredPlaces=filter(lambda x: \\\n",
    "#                               sampleY<=yMaxMap[x[1]]+yAllowance and sampleY>=yMinMap[x[1]]-yAllowance and \\\n",
    "#                               sampleX<=xMaxMap[x[1]] and sampleX>=xMinMap[x[1]] and \\\n",
    "#                               sampleDay<=dayMaxMap[x[1]] and sampleDay>=dayMinMap[x[1]], prob[i])\n",
    "#         if filteredPlaces:\n",
    "#             filteredPlaces=map(lambda x: [x[0]*regionalPoints, x[1]], filteredPlaces)\n",
    "#         regionalPred.append(filteredPlaces)\n",
    "#     return regionalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test(modelSerialization=False, resultSerialization=False, model='rf', predictSet=valid, th=0, xMargin=0.05, yMargin=0.025):\n",
    "    \n",
    "    if modelSerialization or resultSerialization:\n",
    "        base='./'\n",
    "        folderName=model+'-'+time.strftime('%c')\n",
    "        folderPath=base+folderName+'/'\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.makedirs(folderPath)\n",
    "            \n",
    "    \n",
    "#     f=['x','y','xTimeY','xDivY', 'accuracy', 'day', 'weekday', 'hourInDay','hourInDayShifted2', 'month', 'year']\n",
    "    f=['x','y', 'accuracy', 'day','weekday', 'hourInDay','hourInDayShifted2', 'month', 'year']\n",
    "        \n",
    "    count=0\n",
    "    accuracies=[]\n",
    "    FBscores=[]\n",
    "    \n",
    "    startTime=time.time()\n",
    "    trainingTimes=[]\n",
    "    predictionTimes=[]\n",
    "    \n",
    "    testNum=0\n",
    "\n",
    "    roundNum=5\n",
    "\n",
    "    for xNum, yNum in ((xn, yn) for xn in xrange(nXRegions) for yn in xrange(nYRegions)):\n",
    "\n",
    "        xStep=round(1.0*(xMax-xMin)/nXRegions,roundNum)\n",
    "        xStart=round(xMin+xNum*xStep,roundNum)\n",
    "        xEnd=round(xStart+xStep,roundNum)\n",
    "\n",
    "        yStep=round(1.0*(yMax-yMin)/nYRegions,roundNum)\n",
    "        yStart=round(yMin+yNum*yStep,roundNum)\n",
    "        yEnd=round(yStart+yStep,roundNum)\n",
    "        \n",
    "#         regionalTrain=train[(train['x']<xEnd) & (train['x']>=xStart) & (train['y']<yEnd) & (train['y']>=yStart)]\n",
    "\n",
    "        regionalTrain=train[(train['x']<xEnd+xMargin) & (train['x']>=xStart-xMargin) & (train['y']<yEnd+yMargin) & (train['y']>=yStart-yMargin)]\n",
    "#         print xStart, xEnd, yStart, yEnd, len(regionalTrain)\n",
    "\n",
    "        \n",
    "            \n",
    "#         regionalTrain['sampleWeight']=\n",
    "\n",
    "\n",
    "        placesCounts=regionalTrain['place_id'].value_counts()\n",
    "        regionalTrain=regionalTrain[(placeCounts[regionalTrain['place_id'].values]>th).values]\n",
    "        \n",
    "        tail=len(regionalTrain)/6\n",
    "        latest=regionalTrain.sort_values(by=['time'])[:tail]\n",
    "        regionalTrain=regionalTrain.append(latest)\n",
    "        \n",
    "        \n",
    "        addition=regionalTrain[regionalTrain['hourInDay']<=4]\n",
    "        addition['hourInDay']=addition['hourInDay']+24\n",
    "        regionalTrain=regionalTrain.append(addition)\n",
    "        \n",
    "        addition=regionalTrain[regionalTrain['hourInDay']>=20]\n",
    "        addition['hourInDay']=addition['hourInDay']-24\n",
    "        regionalTrain=regionalTrain.append(addition)\n",
    "\n",
    "\n",
    "        \n",
    "        if len(regionalTrain):\n",
    "#             regionalPredictSet=predictSet[(predictSet['x']<xEnd-margin) & (predictSet['x']>=xStart+margin) & (predictSet['y']<yEnd-margin) & (predictSet['y']>=yStart+margin)]\n",
    "            regionalPredictSet=predictSet[(predictSet['x']<xEnd) & (predictSet['x']>=xStart) & (predictSet['y']<yEnd) & (predictSet['y']>=yStart)]\n",
    "\n",
    "            testNum+=len(regionalPredictSet)\n",
    "\n",
    "            if model=='knn':\n",
    "                fWeights={'x': 500, 'y': 1000, 'accuracy':0, 'day': 0,'dayInMonth': 0, 'weekday': 3,\\\n",
    "                          'hourInDay': 4, 'hourInDayShifted2': 0, 'month': 2, 'year': 10}\n",
    "                for ft in f:\n",
    "                    regionalTrain[ft]=regionalTrain[ft].values*fWeights[ft]\n",
    "                    regionalPredictSet[ft]=regionalPredictSet[ft].values*fWeights[ft]\n",
    "                \n",
    "            else:\n",
    "                fMean=regionalTrain[f].mean()\n",
    "                fStd=regionalTrain[f].std()\n",
    "\n",
    "                for ft in f:       \n",
    "                    regionalTrain[ft]=(regionalTrain[ft].values-fMean[ft])/(fStd[ft])\n",
    "                    regionalPredictSet[ft]=(regionalPredictSet[ft].values-fMean[ft])/(fStd[ft])\n",
    "#                 print regionalTrain['x'].describe()\n",
    "\n",
    "      \n",
    "            le=LabelEncoder()\n",
    "            regionalTrain['le']=le.fit_transform(regionalTrain['place_id'].values)\n",
    "\n",
    "#             s_w=1**(15-regionalTrain['day'].values/30.0)\n",
    "            \n",
    "            trainingStartTime=time.time()\n",
    "            if model=='rf':\n",
    "                s_w_rf=3**(-regionalTrain['day'].values)\n",
    "#                 s_w_rf=1.65-regionalTrain['day'].values\n",
    "    #             clf=RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=None).fit(regionalTrain[f], regionalTrain['le'])   \n",
    "            \n",
    "                clf=RandomForestClassifier(n_jobs=-1, n_estimators=150, random_state=0).fit(regionalTrain[f], regionalTrain['le'], sample_weight=s_w_rf)  \n",
    "\n",
    "            if model=='xgb':\n",
    "                clf=XGBClassifier(learning_rate=0.02, n_estimators=220, objective='multi:softprob', max_depth=3, seed=0).fit(regionalTrain[f], regionalTrain['le'])\n",
    "            \n",
    "            \n",
    "            if model=='knn':\n",
    "                clf=KNeighborsClassifier(n_neighbors=25, weights='distance',metric='manhattan', n_jobs=-1).fit(regionalTrain[f], regionalTrain['le'])\n",
    "         \n",
    "            trainingTimes.append(time.time()-trainingStartTime)\n",
    "            \n",
    "            \n",
    "            if modelSerialization:\n",
    "                modelFileName='{:04d}-{}-{}-{}-{}.clf'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                modelFilePath=folderPath+modelFileName\n",
    "                with open(modelFilePath, 'ab+') as fo:\n",
    "                    pickle.dump(clf, fo, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "            predictionStartTime=time.time()\n",
    "            prob=clf.predict_proba(regionalPredictSet[f])\n",
    "            predictionTimes.append(time.time()-predictionStartTime)\n",
    "            \n",
    "            pred=[sorted(zip(p, clf.classes_))[-3:][::-1] for p in prob]\n",
    "            prediction=le.inverse_transform([zip(*p)[1] for p in pred])\n",
    "            confidence=[zip(*p)[0] for p in pred]\n",
    "            \n",
    "            \n",
    "                \n",
    "            fbscoreForSerialization=-1\n",
    "            if 'place_id' in predictSet.columns:\n",
    "                regionalAccuracy=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                regionalConfidence=[sum(z)/len(regionalPredictSet) for z in zip(*confidence)]\n",
    "                regionalConfidence3=sum(regionalConfidence)\n",
    "\n",
    "                fbAccuracy=0\n",
    "                fbAccuracy+=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][:1] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/2*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][1:2] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/3*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][2:3] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                FBscores.append(fbAccuracy)\n",
    "                print 'region {}: {},{} accuracy: {},  fbAccu: {}, confidence: {}:'.format(count, xNum, yNum, regionalAccuracy, fbAccuracy, regionalConfidence3)\n",
    "                accuracies.append(regionalAccuracy)\n",
    "                if resultSerialization:\n",
    "                    fbscoreForSerialization=fbAccuracy\n",
    "                \n",
    "            if resultSerialization:\n",
    "                resultFileName='{:04d}-{}-{}-{}-{}.rst'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                resultFilePath=folderPath+resultFileName\n",
    "                predColumns=zip(*prediction)\n",
    "                confColumns=zip(*confidence)\n",
    "\n",
    "                \n",
    "                if len(predColumns[2])!=len(prediction):\n",
    "                    print 'missing values',count, len(predColumns[0])\n",
    "                \n",
    "                results=pd.DataFrame({'originalIndex': regionalPredictSet['originalIndex'].tolist(),\\\n",
    "                                      'x':regionalPredictSet['x'].tolist(), 'y':regionalPredictSet['y'].tolist(), \\\n",
    "                                      'accuracy':regionalPredictSet['accuracy'].tolist(), 'pred0':predColumns[0], \\\n",
    "                                      'pred1':predColumns[1], 'pred2':predColumns[2], 'conf0': confColumns[0], \\\n",
    "                                      'conf1': confColumns[1], 'conf2': confColumns[2], 'regionalFBScore': [fbscoreForSerialization]*len(regionalPredictSet)})\n",
    "\n",
    "                results.to_csv(resultFilePath)\n",
    "\n",
    "\n",
    "\n",
    "        count+=1\n",
    "        if count%10==0:\n",
    "\n",
    "            print '{} : total time {} s.'.format(count, time.time()-startTime)\n",
    "            print 'Average training Time: ', sum(trainingTimes)/len(trainingTimes)\n",
    "            print 'Average prediction Time: ', sum(predictionTimes)/len(predictionTimes)\n",
    "            print 'Average FB Score', np.mean(FBscores)\n",
    "            print \n",
    "            \n",
    "            startTime=time.time()\n",
    "            trainingTimes=[]\n",
    "            predictionTimes=[]\n",
    "\n",
    "\n",
    "    print \n",
    "    print np.mean(accuracies)\n",
    "    print np.var(accuracies)\n",
    "    print\n",
    "    print np.mean(FBscores)\n",
    "    print testNum\n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region 0: 0,0 accuracy: 0.667400105615,  fbAccu: 0.567769758845, confidence: 0.821161599541:\n",
      "region 1: 0,1 accuracy: 0.623768771193,  fbAccu: 0.524893697185, confidence: 0.809489442031:\n",
      "region 2: 0,2 accuracy: 0.617817324185,  fbAccu: 0.52029731275, confidence: 0.784422061273:\n",
      "region 3: 0,3 accuracy: 0.627004608295,  fbAccu: 0.531597542243, confidence: 0.817409870939:\n",
      "region 4: 0,4 accuracy: 0.639270636845,  fbAccu: 0.539357465792, confidence: 0.818269925486:\n",
      "region 5: 0,5 accuracy: 0.666427289048,  fbAccu: 0.561320566527, confidence: 0.808990489398:\n",
      "region 6: 0,6 accuracy: 0.634086039229,  fbAccu: 0.534682160321, confidence: 0.800761467096:\n",
      "region 7: 0,7 accuracy: 0.68156424581,  fbAccu: 0.579290404783, confidence: 0.82548883015:\n",
      "region 8: 1,0 accuracy: 0.61995584989,  fbAccu: 0.51995584989, confidence: 0.806285073852:\n",
      "region 9: 1,1 accuracy: 0.587030092381,  fbAccu: 0.489283209854, confidence: 0.769848789211:\n",
      "10 : total time 23.9376981258 s.\n",
      "Average training Time:  0.0385636806488\n",
      "Average prediction Time:  0.336292386055\n",
      "Average FB Score 0.536844796819\n",
      "\n",
      "region 10: 1,2 accuracy: 0.631914659628,  fbAccu: 0.526632207926, confidence: 0.801308448816:\n",
      "region 11: 1,3 accuracy: 0.663362022007,  fbAccu: 0.573827940589, confidence: 0.812671305852:\n",
      "region 12: 1,4 accuracy: 0.604438388164,  fbAccu: 0.517422620206, confidence: 0.782851693699:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-27a08896de4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelSerialization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'knn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultSerialization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxMargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.06\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myMargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-0d876ac2f866>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(modelSerialization, resultSerialization, model, predictSet, th, xMargin, yMargin)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mpredictionStartTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregionalPredictSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mpredictionTimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpredictionStartTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/site-packages/sklearn/neighbors/classification.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    397\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    398\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 399\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m             )\n\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiprocessing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/multiprocessing/util.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, wr)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[0;32m    206\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining worker handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mworker_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m             \u001b[0mworker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;31m# Terminate workers which haven't already finished.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    949\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.join(): timed out\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhenjie/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                     \u001b[0m_sleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test(modelSerialization=False, model='knn', resultSerialization=False, predictSet=valid, th=3, xMargin=0.06, yMargin=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeSubmission(resultFolder):\n",
    "    results=[]\n",
    "    for f in os.listdir(resultFolder):\n",
    "        if f.endswith('.rst'):\n",
    "            fi=resultFolder+'/'+f\n",
    "            results.append(pd.read_csv(fi))\n",
    "    results=pd.concat(results)\n",
    "        \n",
    "    results.sort(['originalIndex'], inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('../submissions/xgb-0.03-50Trees/')\n",
    "predictions=results[['pred0','pred1','pred2']]\n",
    "submit=pd.DataFrame()\n",
    "# submit.loc[:,'row_id']=np.arange(len(predictions))\n",
    "submit.loc[:,'place_id']=predictions[['pred0', 'pred1', 'pred2']].apply(lambda x: ' '.join([str(nx) for nx in x]), axis=1)\n",
    "submit.loc[:,'row_id']=np.arange(len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit=submit[['row_id','place_id' ]]\n",
    "submit.set_index('row_id', inplace=True)\n",
    "submit.to_csv('../submissions/xgb0.03_50Trees.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p300=pd.read_csv('../submissions/rf300Trees10_250.csv').head()\n",
    "p50=pd.read_csv('../submissions/rf50Trees10_250.csv').head()\n",
    "p300\n",
    "p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others=pd.read_csv('../submissions/rf_submission_2016-06-03-19-57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('rf-Tue Jun 14 18:18:14 2016')\n",
    "predictions=results[['pred0','pred1','pred2']].values\n",
    "\n",
    "realXMin=0\n",
    "realXMax=10.1\n",
    "realYMin=0\n",
    "realYMax=10.1\n",
    "\n",
    "real=_train_[int(len(_train_)*trainRatio):]\n",
    "\n",
    "real=real[(real['x']<realXMax) & (real['x']>=realXMin) & (real['y']<realYMax) & (real['y']>=realYMin)]\n",
    "real=real[['place_id']]\n",
    "\n",
    "print len(real)\n",
    "print len(predictions)\n",
    "\n",
    "# print len(predictions), len(real), results['originalIndex'].value_counts()\n",
    "\n",
    "totalHit=sum([real['place_id'].iloc[i] in predictions[i] for i in xrange(len(predictions))])\n",
    "score=0\n",
    "score+=1.0*sum([real['place_id'].iloc[i] in predictions[i][:1] for i in xrange(len(predictions))])\n",
    "score+=1.0/2*sum([real['place_id'].iloc[i] in predictions[i][1:2] for i in xrange(len(predictions))])\n",
    "score+=1.0/3*sum([real['place_id'].iloc[i] in predictions[i][2:3] for i in xrange(len(predictions))])\n",
    "\n",
    "print 1.0*totalHit/len(predictions)\n",
    "print score/len(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real.head()\n",
    "\n",
    "results[results['originalIndex']==934546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=pd.read_csv('rf-Sun Jun 12 12:17:04 2016/0000-0.0-1.0-0.0-0.04.rst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
