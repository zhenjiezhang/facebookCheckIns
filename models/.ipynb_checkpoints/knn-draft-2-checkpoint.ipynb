{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Augmentation\n",
      "features done\n",
      "0 th column is done\n",
      "1 th column is done\n",
      "2 th column is done\n",
      "3 th column is done\n",
      "4 th column is done\n",
      "5 th column is done\n",
      "6 th column is done\n",
      "7 th column is done\n",
      "8 th column is done\n",
      "9 th column is done\n",
      "10 th column is done\n",
      "11 th column is done\n",
      "12 th column is done\n",
      "13 th column is done\n",
      "14 th column is done\n",
      "15 th column is done\n",
      "16 th column is done\n",
      "17 th column is done\n",
      "18 th column is done\n",
      "19 th column is done\n",
      "Writing submission file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#print('\tReading train.csv')\n",
    "df_train = pd.read_csv('../input/train.csv',\n",
    "                        usecols=['row_id','x','y','time','place_id','accuracy'], \n",
    "                        index_col = 0)\n",
    "#print('\tReading test.csv')\n",
    "df_test = pd.read_csv('../input/test.csv',\n",
    "                        usecols=['row_id','x','y','time','accuracy'],\n",
    "                        index_col = 0)\n",
    "\n",
    "print('Feature Augmentation')\n",
    "\n",
    "minute = df_train.time%60\n",
    "df_train['hour'] = df_train['time'].div(60).map(int)\n",
    "df_train.drop(['time'], axis=1, inplace=True)\n",
    "df_train['weekday'] = df_train['hour'].div(24).map(int)\n",
    "df_train['month'] = df_train['weekday'].div(30).map(int)\n",
    "## df_train['year'] = (df_train['weekday']//365+1)*10.0\n",
    "df_train['hour'] = ((df_train['hour']%24+1)+minute.div(60.0)).mul(4.0)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "add_data = df_train[df_train.hour<10]# add data for periodic time that hit the boundary\n",
    "add_data.hour = add_data.hour+96\n",
    "\n",
    "add_data2 = df_train[df_train.hour>90]\n",
    "add_data2.hour = add_data2.hour-96\n",
    "\n",
    "df_train = df_train.append(add_data)\n",
    "df_train = df_train.append(add_data2)\n",
    "del add_data,add_data2\n",
    "\n",
    "df_train['weekday'] = (df_train['weekday']%7+1).mul(3.1)\n",
    "df_train['month'] = (df_train['month']%12+1).mul(2.1)\n",
    "df_train['accuracy'] = np.log10(df_train['accuracy']).mul(10.0)\n",
    "\n",
    "minute = df_test['time']%60\n",
    "df_test['hour'] = df_test['time'].div(60)\n",
    "df_test.drop(['time'], axis=1, inplace=True)\n",
    "df_test['weekday'] = df_test['hour'].div(24)\n",
    "df_test['month'] = df_test['weekday'].div(30)\n",
    "## df_test['year'] = (df_test['weekday']//365+1)*10.0\n",
    "df_test['hour'] = ((df_test['hour'].div(24)+1)+minute.div(60.0)).mul(4.0)\n",
    "df_test['weekday'] = (df_test['weekday']%7+1).mul(3.1)\n",
    "df_test['month'] = (df_test['month']%12+1).mul(2.1)\n",
    "df_test['accuracy'] = np.log10(df_test['accuracy']).mul(10.0)\n",
    "\n",
    "print('features done')\n",
    "\n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2\n",
    "\n",
    "def process_one_cell(df_cell_train, df_cell_test):\n",
    "    \n",
    "    #Working on df_train\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= 5).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    \n",
    "    #Working on df_test\n",
    "    row_ids = df_cell_test.index\n",
    "    \n",
    "    #Feature engineering on x and y\n",
    "    df_cell_train.loc[:,'x'] *= 490.0\n",
    "    df_cell_train.loc[:,'y'] *= 980.0\n",
    "    df_cell_test.loc[:,'x'] *= 490.0\n",
    "    df_cell_test.loc[:,'y'] *= 980.0\n",
    "    \n",
    "    #Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values\n",
    "    \n",
    "    #Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=np.floor(np.sqrt(y.size)/5.1282).astype(int), \n",
    "                            weights=calculate_distance,metric='manhattan',n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(df_cell_test.values)\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3]) \n",
    "    \n",
    "    return pred_labels, row_ids\n",
    "   \n",
    "def process_grid(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results\n",
    "    \"\"\"\n",
    "    size = 10.0\n",
    "    x_step = 0.5\n",
    "    y_step = 0.25\n",
    "    \n",
    "    x_border_augment = 0.03  \n",
    "    y_border_augment = 0.015\n",
    "    \n",
    "    preds = np.zeros((df_test.shape[0], 3), dtype=int)\n",
    "\n",
    "    for i in range((int)(size/x_step)):\n",
    "        \n",
    "        x_min = x_step * i\n",
    "        x_max = x_step * (i+1)\n",
    "        x_min = round(x_min, 4)\n",
    "        x_max = round(x_max, 4) \n",
    "        if x_max == size:\n",
    "            x_max = x_max + 0.001\n",
    "            \n",
    "        df_col_train = df_train[(df_train['x'] >= x_min-x_border_augment) & (df_train['x'] < x_max+x_border_augment)]\n",
    "        df_col_test = df_test[(df_test['x'] >= x_min) & (df_test['x'] < x_max)]\n",
    "\n",
    "        for j in range((int)(size/y_step)):\n",
    "            y_min = y_step * j\n",
    "            y_max = y_step * (j+1)\n",
    "            y_min = round(y_min, 4)\n",
    "            y_max = round(y_max, 4)   \n",
    "            if y_max == size:\n",
    "                y_max = y_max + 0.001\n",
    "                \n",
    "            df_cell_train = df_col_train[(df_col_train['y'] >= y_min-y_border_augment) & (df_col_train['y'] < y_max+y_border_augment)]\n",
    "            df_cell_test = df_col_test[(df_col_test['y'] >= y_min) & (df_col_test['y'] < y_max)]\n",
    "            \n",
    "            #Applying classifier to one grid cell\n",
    "            pred_labels, row_ids = process_one_cell(df_cell_train, df_cell_test)\n",
    "\n",
    "            #Updating predictions\n",
    "            preds[row_ids] = pred_labels\n",
    "        print i, 'th column is done'\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def generate_sub(preds):    \n",
    "    print('Writing submission file')\n",
    "    #Auxiliary dataframe with the 3 best predictions for each sample\n",
    "    df_aux = pd.DataFrame(preds, dtype=str, columns=['l1', 'l2', 'l3'])\n",
    "    #Concatenating the 3 predictions for each sample\n",
    "    ds_sub = df_aux.l1.str.cat([df_aux.l2, df_aux.l3], sep=' ')\n",
    "    \n",
    "    #Writting to csv\n",
    "    ds_sub.name = 'place_id'\n",
    "    ds_sub.to_csv('submission_v01.csv', index=True, header=True, index_label='row_id')\n",
    "\n",
    "preds=process_grid(df_train, df_test)\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "generate_sub(preds)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
