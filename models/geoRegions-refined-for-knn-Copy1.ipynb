{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "_train_=pd.read_csv('../input/train.csv')\n",
    "# places=_train_['place_id'].unique()\n",
    "\n",
    "_train_.sort(['time'], inplace=True)\n",
    "trainRatio=0.7\n",
    "train=_train_[:int(len(_train_)*trainRatio)]\n",
    "# train=train[train['accuracy']<1000]\n",
    "\n",
    "valid=_train_[int(len(_train_)*trainRatio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureFactory(dataFrame):\n",
    "    print('Feature Augmentation')\n",
    "    minute = dataFrame.time%60\n",
    "    dataFrame['hour'] = dataFrame['time'].div(60).map(int)\n",
    "#     dataFrame.drop(['time'], axis=1, inplace=True)\n",
    "    dataFrame['weekday'] = dataFrame['hour'].div(24).map(int)\n",
    "    dataFrame['month'] = dataFrame['weekday'].div(30).map(int)\n",
    "#     dataFrame['day']=dataFrame['hour'].div(24).map(int)\n",
    "    \n",
    "    dataFrame['year'] = (dataFrame['weekday'].div(365).map(int)+1)*10.0\n",
    "    dataFrame['hour'] = ((dataFrame.loc[:,'hour'].values%(24)+1)+minute.div(60.0))*(4.0)\n",
    "\n",
    "\n",
    "    dataFrame['weekday'] = (dataFrame['weekday']%7+1)*3.1\n",
    "    dataFrame['month'] = (dataFrame['month']%12+1)*2.1\n",
    "#     dataFrame['dayOfMonth']=(dataFrame['day']%30+1)\n",
    "    dataFrame['accuracy'] = np.log10(dataFrame['accuracy'])*10.0\n",
    "    dataFrame['originalIndex'] = np.arange(len(dataFrame))\n",
    "\n",
    "    print ('processing is done')\n",
    "f=['x','y', 'accuracy','hour', 'weekday', 'month', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def amplifier1(dataFrame):\n",
    "    add_data = dataFrame[dataFrame.hour<10]\n",
    "    add_data.hour = add_data.hour+96\n",
    "    return add_data\n",
    "    \n",
    "def amplifier2(dataFrame):\n",
    "    add_data = dataFrame[dataFrame.hour>90]\n",
    "    add_data.hour = add_data.hour-96\n",
    "    return add_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Augmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhenjie/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing is done\n",
      "Feature Augmentation\n",
      "processing is done\n"
     ]
    }
   ],
   "source": [
    "featureFactory(train)\n",
    "featureFactory(valid)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "ap1=amplifier1(train)\n",
    "ap2=amplifier2(train)\n",
    "train=train.append(ap1).append(ap2)\n",
    "\n",
    "# train=train.append(amplifier1(train))\n",
    "# train=train.append(amplifier2(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test=pd.read_csv('../input/test.csv')\n",
    "# featureFactory(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# g=train.groupby('place_id')\n",
    "# places=pd.DataFrame()\n",
    "# places['xMean']=g['x'].mean()\n",
    "# places['xStd']=g['x'].std()\n",
    "\n",
    "# places['yMean']=g['y'].mean()\n",
    "# places['yStd']=g['y'].std()\n",
    "\n",
    "# sTime=time.time()\n",
    "\n",
    "# nStd=5\n",
    "# train=train[(abs(train['y']-places.loc[train['place_id'], 'yMean'].values)<nStd*places.loc[train['place_id'], 'yStd'].values)\\\n",
    "#          & (abs(train['x']-places.loc[train['place_id'], 'xMean'].values)<nStd*places.loc[train['place_id'], 'xStd'].values)\\\n",
    "           \n",
    "#            ]\n",
    "\n",
    "# print time.time()-sTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.1 0 10.1 20 40\n"
     ]
    }
   ],
   "source": [
    "nXRegions=20\n",
    "nYRegions=40\n",
    "xMin=0\n",
    "xMax=10.1\n",
    "yMin=0\n",
    "yMax=10.1\n",
    "nXRegions=nXRegions*int(xMax-xMin)/10\n",
    "nYRegions=nYRegions*int(yMax-yMin)/10\n",
    "# train=train[(train['x']<xMax) & (train['x']>=xMin) & (train['y']<yMax) & (train['y']>=yMin)]\n",
    "# valid=valid[(valid['x']<xMax) & (valid['x']>=xMin) & (valid['y']<yMax) & (valid['y']>=yMin)]\n",
    "\n",
    "print xMin, xMax, yMin, yMax, nXRegions, nYRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def regionalForestPred(pred, classes, regionalPoints, data):\n",
    "\n",
    "    \n",
    "#     prob=[sorted(zip(p, classes))[-3:][::-1] for p in pred]\n",
    "    \n",
    "    \n",
    "#     regionalPred=[]\n",
    "#     for i in xrange(len(data)):\n",
    "#         sampleY=data['y'].iloc[i]\n",
    "#         sampleX=data['x'].iloc[i]\n",
    "#         sampleDay=data['day'].iloc[i]\n",
    "\n",
    "#         filteredPlaces=filter(lambda x: \\\n",
    "#                               sampleY<=yMaxMap[x[1]]+yAllowance and sampleY>=yMinMap[x[1]]-yAllowance and \\\n",
    "#                               sampleX<=xMaxMap[x[1]] and sampleX>=xMinMap[x[1]] and \\\n",
    "#                               sampleDay<=dayMaxMap[x[1]] and sampleDay>=dayMinMap[x[1]], prob[i])\n",
    "#         if filteredPlaces:\n",
    "#             filteredPlaces=map(lambda x: [x[0]*regionalPoints, x[1]], filteredPlaces)\n",
    "#         regionalPred.append(filteredPlaces)\n",
    "#     return regionalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test(modelSerialization=False, resultSerialization=False, model='rf', predictSet=valid, th=0, xMargin=0.05, yMargin=0.025):\n",
    "    \n",
    "    if modelSerialization or resultSerialization:\n",
    "        base='./'\n",
    "        folderName=model+'-'+time.strftime('%c')\n",
    "        folderPath=base+folderName+'/'\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.makedirs(folderPath)\n",
    "            \n",
    "    f=['x','y', 'accuracy','hour', 'weekday','month', 'year']\n",
    "\n",
    "        \n",
    "    count=0\n",
    "    accuracies=[]\n",
    "    FBscores=[]\n",
    "    \n",
    "    startTime=time.time()\n",
    "    trainingTimes=[]\n",
    "    predictionTimes=[]\n",
    "    \n",
    "    testNum=0\n",
    "\n",
    "    roundNum=5\n",
    "\n",
    "    for xNum, yNum in ((xn, yn) for xn in xrange(nXRegions) for yn in xrange(nYRegions)):\n",
    "\n",
    "        xStep=round(1.0*(xMax-xMin)/nXRegions,roundNum)\n",
    "        xStart=round(xMin+xNum*xStep,roundNum)\n",
    "        xEnd=round(xStart+xStep,roundNum)\n",
    "\n",
    "        yStep=round(1.0*(yMax-yMin)/nYRegions,roundNum)\n",
    "        yStart=round(yMin+yNum*yStep,roundNum)\n",
    "        yEnd=round(yStart+yStep,roundNum)\n",
    "        \n",
    "\n",
    "        regionalTrain=train[(train['x']<xEnd+xMargin) & (train['x']>=xStart-xMargin) & (train['y']<yEnd+yMargin) & (train['y']>=yStart-yMargin)]\n",
    "#         print xStart, xEnd, yStart, yEnd, len(regionalTrain)\n",
    "\n",
    "\n",
    "\n",
    "        placesCounts=regionalTrain['place_id'].value_counts()\n",
    "        regionalTrain=regionalTrain[(placesCounts[regionalTrain['place_id'].values]>=th).values]\n",
    "#        this is no good, neight :tail or -tail:\n",
    "#         tail=len(regionalTrain)/20\n",
    "#         latest=regionalTrain.sort_values(by=['time'])[-tail:]\n",
    "#         regionalTrain=regionalTrain.append(latest)\n",
    "        \n",
    "        \n",
    "#         addition=regionalTrain[regionalTrain['hourInDay']<=4]\n",
    "#         addition['hourInDay']=addition['hourInDay']+24\n",
    "#         regionalTrain=regionalTrain.append(addition)\n",
    "        \n",
    "#         addition=regionalTrain[regionalTrain['hourInDay']>=20]\n",
    "#         addition['hourInDay']=addition['hourInDay']-24\n",
    "#         regionalTrain=regionalTrain.append(addition)\n",
    "\n",
    "\n",
    "        \n",
    "        if len(regionalTrain):\n",
    "            regionalPredictSet=predictSet[(predictSet['x']<xEnd) & (predictSet['x']>=xStart) & (predictSet['y']<yEnd) & (predictSet['y']>=yStart)]\n",
    "            testNum+=len(regionalPredictSet)\n",
    "\n",
    "            if model=='knn':\n",
    "                regionalTrain.loc[:,'x'] *= 490.0\n",
    "                regionalTrain.loc[:,'y'] *= 980.0\n",
    "                regionalPredictSet.loc[:,'x'] *= 490.0\n",
    "                regionalPredictSet.loc[:,'y'] *= 980.0\n",
    "\n",
    "                \n",
    "            else:\n",
    "                regionalTrain.loc[:,'x'] *= 490.0\n",
    "                regionalTrain.loc[:,'y'] *= 980.0\n",
    "                regionalPredictSet.loc[:,'x'] *= 490.0\n",
    "                regionalPredictSet.loc[:,'y'] *= 980.0\n",
    "                \n",
    "#                 fMean=regionalTrain[f].mean()\n",
    "#                 fStd=regionalTrain[f].std()\n",
    "\n",
    "#                 for ft in f:       \n",
    "#                     regionalTrain[ft]=(regionalTrain[ft].values-fMean[ft])/(fStd[ft])\n",
    "#                     regionalPredictSet[ft]=(regionalPredictSet[ft].values-fMean[ft])/(fStd[ft])\n",
    "\n",
    "\n",
    "      \n",
    "            le=LabelEncoder()\n",
    "            regionalTrain['le']=le.fit_transform(regionalTrain['place_id'].values)\n",
    "\n",
    "#             s_w=1**(15-regionalTrain['day'].values/30.0)\n",
    "            \n",
    "            trainingStartTime=time.time()\n",
    "            if model=='rf':\n",
    "#                 s_w_rf=3**(-regionalTrain['month'].values*30)\n",
    "#                 s_w_rf=1.65-regionalTrain['day'].values\n",
    "                s_w_rf=np.ones(len(regionalTrain))\n",
    "\n",
    "    #             clf=RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=None).fit(regionalTrain[f], regionalTrain['le'])   \n",
    "            \n",
    "                clf=RandomForestClassifier(n_jobs=-1, n_estimators=150, random_state=0).fit(regionalTrain[f], regionalTrain['le'], sample_weight=s_w_rf)  \n",
    "\n",
    "            if model=='xgb':\n",
    "                clf=XGBClassifier(learning_rate=0.02, n_estimators=220, objective='multi:softprob', max_depth=3, seed=0).fit(regionalTrain[f], regionalTrain['le'])\n",
    "            \n",
    "            \n",
    "            if model=='knn':\n",
    "                def calculate_distance(distances):\n",
    "                    return distances ** -2\n",
    "#                 clf=KNeighborsClassifier(n_neighbors=25, weights='distance',metric='manhattan', n_jobs=-1).fit(regionalTrain[f], regionalTrain['le'])\n",
    "#                 numNeighbors=np.floor(np.sqrt(len(regionalPredictSet))/5.1282).astype(int)\n",
    "                numNeighbors=np.floor(0.3*np.sqrt(len(regionalPredictSet)))\n",
    "#                 numNeighbors=36\n",
    "\n",
    "\n",
    "                clf=KNeighborsClassifier(n_neighbors=numNeighbors, weights=calculate_distance, metric='manhattan', n_jobs=-1).fit(regionalTrain[f], regionalTrain['le'])\n",
    "\n",
    "         \n",
    "            trainingTimes.append(time.time()-trainingStartTime)\n",
    "            \n",
    "            \n",
    "            if modelSerialization:\n",
    "                modelFileName='{:04d}-{}-{}-{}-{}.clf'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                modelFilePath=folderPath+modelFileName\n",
    "                with open(modelFilePath, 'ab+') as fo:\n",
    "                    pickle.dump(clf, fo, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "            predictionStartTime=time.time()\n",
    "            prob=clf.predict_proba(regionalPredictSet[f])\n",
    "            predictionTimes.append(time.time()-predictionStartTime)\n",
    "            \n",
    "            pred=[sorted(zip(p, clf.classes_))[-3:][::-1] for p in prob]\n",
    "            prediction=le.inverse_transform([zip(*p)[1] for p in pred])\n",
    "            confidence=[zip(*p)[0] for p in pred]\n",
    "            \n",
    "            \n",
    "                \n",
    "            fbscoreForSerialization=-1\n",
    "            if 'place_id' in predictSet.columns:\n",
    "                regionalAccuracy=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                regionalConfidence=[sum(z)/len(regionalPredictSet) for z in zip(*confidence)]\n",
    "                regionalConfidence3=sum(regionalConfidence)\n",
    "\n",
    "                fbAccuracy=0\n",
    "                fbAccuracy+=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][:1] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/2*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][1:2] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/3*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][2:3] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                FBscores.append(fbAccuracy)\n",
    "                print 'region {}: {},{} accuracy: {},  fbAccu: {}, confidence: {}:'.format(count, xNum, yNum, regionalAccuracy, fbAccuracy, regionalConfidence3)\n",
    "                accuracies.append(regionalAccuracy)\n",
    "                if resultSerialization:\n",
    "                    fbscoreForSerialization=fbAccuracy\n",
    "                \n",
    "            if resultSerialization:\n",
    "                resultFileName='{:04d}-{}-{}-{}-{}.rst'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                resultFilePath=folderPath+resultFileName\n",
    "                predColumns=zip(*prediction)\n",
    "                confColumns=zip(*confidence)\n",
    "\n",
    "                \n",
    "                if len(predColumns[2])!=len(prediction):\n",
    "                    print 'missing values',count, len(predColumns[0])\n",
    "                \n",
    "                results=pd.DataFrame({'originalIndex': regionalPredictSet['originalIndex'].tolist(),\\\n",
    "                                      'x':regionalPredictSet['x'].tolist(), 'y':regionalPredictSet['y'].tolist(), \\\n",
    "                                      'accuracy':regionalPredictSet['accuracy'].tolist(), 'pred0':predColumns[0], \\\n",
    "                                      'pred1':predColumns[1], 'pred2':predColumns[2], 'conf0': confColumns[0], \\\n",
    "                                      'conf1': confColumns[1], 'conf2': confColumns[2],'real':regionalPredictSet['place_id'], 'regionalFBScore': [fbscoreForSerialization]*len(regionalPredictSet)})\n",
    "\n",
    "                results.to_csv(resultFilePath)\n",
    "\n",
    "\n",
    "\n",
    "        count+=1\n",
    "        if count%10==0:\n",
    "\n",
    "            print '{} : total time {} s.'.format(count, time.time()-startTime)\n",
    "            print 'Average training Time: ', sum(trainingTimes)/len(trainingTimes)\n",
    "            print 'Average prediction Time: ', sum(predictionTimes)/len(predictionTimes)\n",
    "            print 'Average FB Score', np.mean(FBscores)\n",
    "            print \n",
    "            \n",
    "            startTime=time.time()\n",
    "            trainingTimes=[]\n",
    "            predictionTimes=[]\n",
    "\n",
    "\n",
    "    print \n",
    "    print np.mean(accuracies)\n",
    "    print np.var(accuracies)\n",
    "    print\n",
    "    print np.mean(FBscores)\n",
    "    print testNum\n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region 0: 0,0 accuracy: 0.671726267044,  fbAccu: 0.574879227053, confidence: 0.593812423177:\n",
      "region 1: 0,1 accuracy: 0.626410564226,  fbAccu: 0.53081232493, confidence: 0.58595811658:\n",
      "region 2: 0,2 accuracy: 0.62591298825,  fbAccu: 0.535125789492, confidence: 0.576627500794:\n",
      "region 3: 0,3 accuracy: 0.628838335784,  fbAccu: 0.538332900845, confidence: 0.597537698584:\n",
      "region 4: 0,4 accuracy: 0.646956997085,  fbAccu: 0.549927113703, confidence: 0.577670068027:\n",
      "region 5: 0,5 accuracy: 0.671538727126,  fbAccu: 0.569167913454, confidence: 0.569301415583:\n",
      "region 6: 0,6 accuracy: 0.647269763651,  fbAccu: 0.554794892692, confidence: 0.577138277642:\n",
      "region 7: 0,7 accuracy: 0.680975143403,  fbAccu: 0.586759082218, confidence: 0.604026131294:\n",
      "region 8: 0,8 accuracy: 0.629863776624,  fbAccu: 0.529000777703, confidence: 0.598486239683:\n",
      "region 9: 0,9 accuracy: 0.674102230669,  fbAccu: 0.57503917842, confidence: 0.586065152879:\n",
      "10 : total time 85.9319849014 s.\n",
      "Average training Time:  5.59877393246\n",
      "Average prediction Time:  1.37728710175\n",
      "Average FB Score 0.554383920051\n",
      "\n",
      "region 10: 0,10 accuracy: 0.656365438328,  fbAccu: 0.559960356789, confidence: 0.615884914557:\n"
     ]
    }
   ],
   "source": [
    "train_test(modelSerialization=False, model='rf', resultSerialization=True, predictSet=valid, th=5, xMargin=0.03, yMargin=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeSubmission(resultFolder):\n",
    "    results=[]\n",
    "    for f in os.listdir(resultFolder):\n",
    "        if f.endswith('.rst'):\n",
    "            fi=resultFolder+'/'+f\n",
    "            results.append(pd.read_csv(fi))\n",
    "    results=pd.concat(results)\n",
    "        \n",
    "    results.sort(['originalIndex'], inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('../submissions/xgb-0.03-50Trees/')\n",
    "predictions=results[['pred0','pred1','pred2']]\n",
    "submit=pd.DataFrame()\n",
    "# submit.loc[:,'row_id']=np.arange(len(predictions))\n",
    "submit.loc[:,'place_id']=predictions[['pred0', 'pred1', 'pred2']].apply(lambda x: ' '.join([str(nx) for nx in x]), axis=1)\n",
    "submit.loc[:,'row_id']=np.arange(len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit=submit[['row_id','place_id' ]]\n",
    "submit.set_index('row_id', inplace=True)\n",
    "submit.to_csv('../submissions/xgb0.03_50Trees.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p300=pd.read_csv('../submissions/rf300Trees10_250.csv').head()\n",
    "p50=pd.read_csv('../submissions/rf50Trees10_250.csv').head()\n",
    "p300\n",
    "p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others=pd.read_csv('../submissions/rf_submission_2016-06-03-19-57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('rf-Tue Jun 14 18:18:14 2016')\n",
    "predictions=results[['pred0','pred1','pred2']].values\n",
    "\n",
    "realXMin=0\n",
    "realXMax=10.1\n",
    "realYMin=0\n",
    "realYMax=10.1\n",
    "\n",
    "real=_train_[int(len(_train_)*trainRatio):]\n",
    "\n",
    "real=real[(real['x']<realXMax) & (real['x']>=realXMin) & (real['y']<realYMax) & (real['y']>=realYMin)]\n",
    "real=real[['place_id']]\n",
    "\n",
    "print len(real)\n",
    "print len(predictions)\n",
    "\n",
    "# print len(predictions), len(real), results['originalIndex'].value_counts()\n",
    "\n",
    "totalHit=sum([real['place_id'].iloc[i] in predictions[i] for i in xrange(len(predictions))])\n",
    "score=0\n",
    "score+=1.0*sum([real['place_id'].iloc[i] in predictions[i][:1] for i in xrange(len(predictions))])\n",
    "score+=1.0/2*sum([real['place_id'].iloc[i] in predictions[i][1:2] for i in xrange(len(predictions))])\n",
    "score+=1.0/3*sum([real['place_id'].iloc[i] in predictions[i][2:3] for i in xrange(len(predictions))])\n",
    "\n",
    "print 1.0*totalHit/len(predictions)\n",
    "print score/len(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real.head()\n",
    "\n",
    "results[results['originalIndex']==934546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=pd.read_csv('rf-Sun Jun 12 12:17:04 2016/0000-0.0-1.0-0.0-0.04.rst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
