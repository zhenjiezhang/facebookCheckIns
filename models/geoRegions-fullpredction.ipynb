{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv')\n",
    "test=pd.read_csv('../input/test.csv')\n",
    "\n",
    "places=train['place_id'].unique()\n",
    "train=train[train['accuracy']>2]\n",
    "placeCounts=train['place_id'].value_counts()\n",
    "train=train[(placeCounts[train['place_id']]>10).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureFactory(dataFrame):\n",
    "    dataFrame.loc[:,'day']=dataFrame.loc[:, 'time'].div(1440).map(int)\n",
    "    dataFrame.loc[:,'weekday']=dataFrame.loc[:,'day']%7\n",
    "    dataFrame.loc[:,'year']=dataFrame.loc[:,'day'].div(365).map(int)\n",
    "    dataFrame.loc[:,'month']=(dataFrame.loc[:,'day']%365).div(30).map(int)\n",
    "    dataFrame.loc[:,'hour']=dataFrame.loc[:,'time'].div(60).map(int)\n",
    "    dataFrame.loc[:, 'hourInDay']=dataFrame.loc[:,'hour']%24\n",
    "    \n",
    "    dataFrame.loc[:, 'originalIndex']=xrange(len(dataFrame))\n",
    "\n",
    "    \n",
    "featureFactory(train)\n",
    "featureFactory(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g=train.groupby('place_id')\n",
    "places=pd.DataFrame()\n",
    "places['xMean']=g['x'].mean()\n",
    "places['xStd']=g['x'].std()\n",
    "\n",
    "places['yMean']=g['y'].mean()\n",
    "places['yStd']=g['y'].std()\n",
    "\n",
    "# places['hourInDayMean']=g['hourInDay'].mean()\n",
    "# places['hourInDayStd']=g['hourInDay'].std()\n",
    "\n",
    "# places['monthMean']=g['month'].mean()\n",
    "# places['monthStd']=g['month'].std()\n",
    "\n",
    "# places['dayMean']=g['day'].mean()\n",
    "# places['dayStd']=g['day'].std()\n",
    "\n",
    "train=train[(abs(train['y']-places.loc[train['place_id'], 'yMean'].values)<5*places.loc[train['place_id'], 'yStd'].values)\\\n",
    "         & (abs(train['x']-places.loc[train['place_id'], 'xMean'].values)<5*places.loc[train['place_id'], 'xStd'].values)\\\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nXRegions=50\n",
    "nYRegions=50\n",
    "\n",
    "xMin=0\n",
    "xMax=10.1\n",
    "yMin=0\n",
    "yMax=10.1\n",
    "nXRegions=nXRegions*int(xMax-xMin)/10\n",
    "nYRegions=nYRegions*int(yMax-yMin)/10\n",
    "train=train[(train['x']<xMax) & (train['x']>=xMin) & (train['y']<yMax) & (train['y']>=yMin)]\n",
    "f=['x','y','accuracy', 'time', 'weekday', 'hourInDay', 'month', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test(modelSerialization=False, resultSerialization=False, model='rf', predictSet=test):\n",
    "    \n",
    "    \n",
    "\n",
    "    if modelSerialization or resultSerialization:\n",
    "        base='./'\n",
    "        folderName=model+'-'+time.strftime('%c')\n",
    "        folderPath=base+folderName+'/'\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.makedirs(folderPath)\n",
    "            \n",
    "        \n",
    "    count=0\n",
    "    accuracies=[]\n",
    "    FBscores=[]\n",
    "    \n",
    "    startTime=time.time()\n",
    "    trainingTimes=[]\n",
    "    predictionTimes=[]\n",
    "    \n",
    "    testNum=0\n",
    "\n",
    "    roundNum=5\n",
    "    for xNum, yNum in ((xn, yn) for xn in xrange(nXRegions) for yn in xrange(nYRegions)):\n",
    "\n",
    "        xStep=round(1.0*(xMax-xMin)/nXRegions,roundNum)\n",
    "        xStart=round(xNum*xStep,roundNum)\n",
    "        xEnd=round(xStart+xStep,roundNum)\n",
    "\n",
    "        yStep=round(1.0*(yMax-yMin)/nYRegions,roundNum)\n",
    "        yStart=round(yNum*yStep,roundNum)\n",
    "        yEnd=round(yStart+yStep,roundNum)\n",
    "\n",
    "        regionalTrain=train[(train['x']<xEnd) & (train['x']>=xStart) & (train['y']<yEnd) & (train['y']>=yStart)]\n",
    "#         regionalTrain['sampleWeight']=\n",
    "\n",
    "        if len(regionalTrain):\n",
    "            regionalPredictSet=predictSet[(predictSet['x']<xEnd) & (predictSet['x']>=xStart) & (predictSet['y']<yEnd) & (predictSet['y']>=yStart)]\n",
    "            testNum+=len(regionalPredictSet)\n",
    "            \n",
    "            s_w_rf=19-regionalTrain['day'].values/30.0\n",
    "            s_w=12-regionalTrain['day'].values/30.0\n",
    "            \n",
    "            trainingStartTime=time.time()\n",
    "#             clf=RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=None).fit(regionalTrain[f], regionalTrain['place_id'])   \n",
    "#             clf=RandomForestClassifier(n_jobs=-1, n_estimators=300, random_state=0).fit(regionalTrain[f], regionalTrain['place_id'], sample_weight=s_w_rf)  \n",
    "            clf=XGBClassifier(learning_rate=0.04, n_estimators=150, objective='multi:softprob').fit(regionalTrain[f], regionalTrain['place_id'])\n",
    "\n",
    "            trainingTimes.append(time.time()-trainingStartTime)\n",
    "            \n",
    "            \n",
    "            if modelSerialization:\n",
    "                modelFileName='{:04d}-{}-{}-{}-{}.clf'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                modelFilePath=folderPath+modelFileName\n",
    "                with open(modelFilePath, 'ab+') as fo:\n",
    "                    pickle.dump(clf, fo, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "            predictionStartTime=time.time()\n",
    "            prob=clf.predict_proba(regionalPredictSet[f])\n",
    "            predictionTimes.append(time.time()-predictionStartTime)\n",
    "            \n",
    "            pred=[sorted(zip(p, clf.classes_))[-3:][::-1] for p in prob]\n",
    "            prediction=[zip(*p)[1] for p in pred]\n",
    "            confidence=[zip(*p)[0] for p in pred]\n",
    "            \n",
    "            \n",
    "                \n",
    "            fbscoreForSerialization=-1\n",
    "            if 'place_id' in predictSet.columns:\n",
    "                regionalAccuracy=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                regionalConfidence=[sum(z)/len(regionalPredictSet) for z in zip(*confidence)]\n",
    "                regionalConfidence3=sum(regionalConfidence)\n",
    "\n",
    "                fbAccuracy=0\n",
    "                fbAccuracy+=1.0*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][:1] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/2*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][1:2] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                fbAccuracy+=1.0/3*sum([regionalPredictSet['place_id'].iloc[i] in prediction[i][2:3] for i in xrange(len(regionalPredictSet))])/len(regionalPredictSet)\n",
    "                FBscores.append(fbAccuracy)\n",
    "                print 'region {}: {},{} accuracy: {},  fbAccu: {}, confidence: {}:'.format(count, xNum, yNum, regionalAccuracy, fbAccuracy, regionalConfidence3)\n",
    "                accuracies.append(regionalAccuracy)\n",
    "                if resultSerialization:\n",
    "                    fbscoreForSerialization=fbAccuracy\n",
    "                \n",
    "            if resultSerialization:\n",
    "                resultFileName='{:04d}-{}-{}-{}-{}.rst'.format(count, xStart, xEnd, yStart, yEnd)\n",
    "                resultFilePath=folderPath+resultFileName\n",
    "                predColumns=zip(*prediction)\n",
    "                confColumns=zip(*confidence)\n",
    "\n",
    "                \n",
    "                if len(predColumns[2])!=len(prediction):\n",
    "                    print 'missing values',count, len(predColumns[0])\n",
    "                \n",
    "                results=pd.DataFrame({'originalIndex': regionalPredictSet['originalIndex'].tolist(),\\\n",
    "                                      'x':regionalPredictSet['x'].tolist(), 'y':regionalPredictSet['y'].tolist(), \\\n",
    "                                      'accuracy':regionalPredictSet['accuracy'].tolist(), 'pred0':predColumns[0], \\\n",
    "                                      'pred1':predColumns[1], 'pred2':predColumns[2], 'conf0': confColumns[0], \\\n",
    "                                      'conf1': confColumns[1], 'conf2': confColumns[2], 'regionalFBScore': [fbscoreForSerialization]*len(regionalPredictSet)})\n",
    "\n",
    "                results.to_csv(resultFilePath)\n",
    "\n",
    "\n",
    "\n",
    "        count+=1\n",
    "        if count%10==0:\n",
    "\n",
    "            print '{} : total time {} s.'.format(count, time.time()-startTime)\n",
    "            print 'Average training Time: ', sum(trainingTimes)/len(trainingTimes)\n",
    "            print 'Average prediction Time: ', sum(predictionTimes)/len(predictionTimes)\n",
    "            print 'Average FB Score', np.mean(FBscores)\n",
    "            print \n",
    "            \n",
    "            startTime=time.time()\n",
    "            trainingTimes=[]\n",
    "            predictionTimes=[]\n",
    "\n",
    "\n",
    "    print \n",
    "    print np.mean(accuracies)\n",
    "    print np.var(accuracies)\n",
    "    print\n",
    "    print np.mean(FBscores)\n",
    "    print testNum\n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ec9aa8ae1d71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelSerialization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultSerialization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'valid' is not defined"
     ]
    }
   ],
   "source": [
    "train_test(modelSerialization=False, resultSerialization=True, predictSet=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeSubmission(resultFolder):\n",
    "    results=[]\n",
    "    for f in os.listdir(resultFolder):\n",
    "        if f.endswith('.rst'):\n",
    "            fi=resultFolder+'/'+f\n",
    "            results.append(pd.read_csv(fi))\n",
    "    results=pd.concat(results)\n",
    "        \n",
    "    results.sort_values(by=['originalIndex'], inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=makeSubmission('../submissions/knn-th8-50-50-nbr25-xm0.06-ym0.03/')\n",
    "predictions=results[['pred0','pred1','pred2']]\n",
    "submit=pd.DataFrame()\n",
    "# submit.loc[:,'row_id']=np.arange(len(predictions))\n",
    "submit.loc[:,'place_id']=predictions[['pred0', 'pred1', 'pred2']].apply(lambda x: ' '.join([str(nx) for nx in x]), axis=1)\n",
    "submit.loc[:,'row_id']=results['originalIndex']\n",
    "\n",
    "submit=submit[['row_id','place_id' ]]\n",
    "submit.set_index('row_id', inplace=True)\n",
    "submit.to_csv('../submissions/knn-th8-50-50-nbr25-xm0.06-ym0.03.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8268854"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8607230"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "row_id      8607229.0\n",
       "x                10.0\n",
       "y                10.0\n",
       "accuracy       1026.0\n",
       "time        1006589.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)\n",
    "test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8607229"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['originalIndex'].max()\n",
    "pd.read_csv('../submissions/rf100Trees50-50Fulltraining.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def supFile(base, sup):\n",
    "    base=pd.read_csv(base)\n",
    "    existingIndex=set(base['row_id'])\n",
    "    supFile=pd.read_csv(sup)\n",
    "    missing=supFile.loc[~(supFile.loc[:,'row_id'].isin(existingIndex)),:]\n",
    "    base=base.append(missing)\n",
    "    base.sort_values(by=['row_id'], inplace=True)\n",
    "    return base\n",
    "base='../submissions/rf300Trees-100-100-margin0.05Full.csv'\n",
    "sup='../submissions/rf300Trees_50_50_full_weightExp1.2base.csv'\n",
    "fixed=supFile(base, sup)\n",
    "fixed.set_index('row_id', inplace=True)\n",
    "fixed.to_csv(base[:-4]+'-fixed'+'.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4393146716 6131996960 3831655216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2465239230 9801651394 6089233511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2516481553 7862615088 2653128693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7995458948 3243409743 5345410711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8711861736 8277155346 4764406629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                          place_id\n",
       "0       0  4393146716 6131996960 3831655216\n",
       "1       1  2465239230 9801651394 6089233511\n",
       "2       2  2516481553 7862615088 2653128693\n",
       "3       3  7995458948 3243409743 5345410711\n",
       "4       4  8711861736 8277155346 4764406629"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=pd.read_csv(base[:-4]+'-fixed'+'.csv')\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
