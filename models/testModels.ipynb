{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "x_threshold = 0.025\n",
    "y_threshold = 0.0125\n",
    "\n",
    "# area 10km by 10 km is divided into grids of size 20x40\n",
    "grid_size = 10.0\n",
    "x_step = 0.5\n",
    "y_step = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Feature engineering\n",
    "    \"\"\"\n",
    "\n",
    "    minute = df.time % 60\n",
    "    df['hour'] = df['time'].div(60).map(int)\n",
    "#     df.drop(['time'], axis=1, inplace=True)\n",
    "    df['weekday'] = df['hour'].div(24).map(int)\n",
    "    df['month'] = df['weekday'].div(30).map(int)\n",
    "    df['year'] = (df['weekday'].div(365).map(int) + 1) * 10.0\n",
    "    df['hour'] = ((df['hour'] % 24 + 1) + minute.div(60.0)) * 4.0\n",
    "    df['weekday'] = (df['weekday'] % 7 + 1) * 3.1\n",
    "    df['month'] = (df['month'] % 12 + 1) * 2.1\n",
    "    df['accuracy'] = np.log10(df['accuracy']) * 10.0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_one_cell(df_train, df_test, th, x_min, y_min, x_max, y_max, method='rf', gridNum=0, cpuCores=-1):\n",
    "    \"\"\"   \n",
    "    Classification inside one grid cell.\n",
    "    \"\"\"\n",
    "\n",
    "    x_min_th = x_min - x_threshold\n",
    "    y_min_th = y_min - y_threshold\n",
    "    x_max_th = x_max + x_threshold\n",
    "    y_max_th = y_max + y_threshold\n",
    "\n",
    "    # Working on df_train, getting few extra points outside this grid\n",
    "    df_cell_train = df_train[(df_train['x'] >= x_min_th)\n",
    "                             & (df_train['x'] <= x_max_th)\n",
    "                             & (df_train['y'] >= y_min_th)\n",
    "                             & (df_train['y'] <= y_max_th)]\n",
    "\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    # Feature engineering on x and y for test\n",
    "    df_cell_train.loc[:, 'x'] *= 490.0\n",
    "    df_cell_train.loc[:, 'y'] *= 980.0\n",
    "\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "\n",
    "    # Working on df_test\n",
    "    df_cell_test = df_test[(df_test['x'] >= x_min_th) & (df_test['x'] <= x_max_th) &\n",
    "                           (df_test['y'] >= y_min_th) & (df_test['y'] <= y_max_th)]\n",
    "    row_ids = df_cell_test.index\n",
    "    # Feature engineering on x and y for test\n",
    "    df_cell_test.loc[:, 'x'] *= 490.0\n",
    "    df_cell_test.loc[:, 'y'] *= 980.0\n",
    "\n",
    "    \n",
    "\n",
    "    # Applying the classifier\n",
    "    rf_sample_weight=np.log10(20+df_cell_train.time.div(1440.0).values/30)**3\n",
    "\n",
    "    df_cell_train.drop(['time'], axis=1, inplace=True)\n",
    "\n",
    "    df_cell_test.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    # Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values\n",
    "    X_test = df_cell_test.values if mode=='test' else df_cell_test.drop(['place_id'], axis=1).values\n",
    "    \n",
    "    \n",
    "    if method=='rf':\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=330, max_depth=None, n_jobs=cpuCores, min_samples_split=4,\n",
    "                                 random_state=0)\n",
    "        clf.fit(X, y, sample_weight=rf_sample_weight)\n",
    "#         clf.fit(X, y)\n",
    "        \n",
    "    elif method=='xgb':\n",
    "        clf=XGBClassifier(learning_rate=0.04, n_estimators=150, objective='multi:softprob', max_depth=3, seed=0, n_jobs=cpuCores)\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "    elif method=='knn':\n",
    "        def calculate_distance(distances):\n",
    "            return distances ** -2\n",
    "\n",
    "        numNeighbors=np.floor(np.sqrt(len(df_cell_train))/5.1282).astype(int)\n",
    "#         numNeighbors=36\n",
    "        clf=KNeighborsClassifier(n_neighbors=numNeighbors, weights=calculate_distance, metric='manhattan', n_jobs=cpuCores)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "    \n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    le_labels=np.argsort(y_pred, axis=1)[:, ::-1][:, :6]\n",
    "    pred_labels = le.inverse_transform(le_labels)\n",
    "    pred_confs=[y_pred[i,le_labels[i]] for i in xrange(len(y_pred))]\n",
    "    \n",
    "    if 'place_id' in df_cell_test.columns:\n",
    "        regionalAccuracy=1.0*sum([df_cell_test['place_id'].iloc[i] in pred_labels[i] for i in xrange(len(df_cell_test))])/len(df_cell_test)\n",
    "        regionalConfidence=[sum(z)/len(df_cell_test) for z in zip(*pred_confs)]\n",
    "        regionalConfidence3=sum(regionalConfidence)\n",
    "\n",
    "        fbAccuracy=0\n",
    "        fbScores0=[df_cell_test['place_id'].iloc[i] in pred_labels[i][:1] for i in xrange(len(df_cell_test))]\n",
    "        fbAccuracy+=1.0*sum([df_cell_test['place_id'].iloc[i] in pred_labels[i][:1] for i in xrange(len(df_cell_test))])/len(df_cell_test)\n",
    "        fbAccuracy+=1.0/2*sum([df_cell_test['place_id'].iloc[i] in pred_labels[i][1:2] for i in xrange(len(df_cell_test))])/len(df_cell_test)\n",
    "        fbAccuracy+=1.0/3*sum([df_cell_test['place_id'].iloc[i] in pred_labels[i][2:3] for i in xrange(len(df_cell_test))])/len(df_cell_test)\n",
    "        FBscores.append(fbAccuracy)\n",
    "        print 'region {}: {},{} accuracy: {},  fbAccu: {}, confidence: {}:'.format(gridNum, x_min, y_min, regionalAccuracy, fbAccuracy, regionalConfidence3)\n",
    "        accuracies.append(regionalAccuracy)\n",
    "\n",
    "\n",
    "    return pred_labels, pred_confs, row_ids\n",
    "\n",
    "\n",
    "def process_grid(df_train, df_test, th, mode='valid', method='rf', note='', cpuCores=-1):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results and makes the\n",
    "    submission.\n",
    "    \"\"\"\n",
    "    base='./'\n",
    "    folderName=method+'-'+time.strftime('%c')\n",
    "    folderPath=base+folderName+'/'\n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "        \n",
    "        \n",
    "            \n",
    "    preds = np.zeros((df_test.shape[0], 6), dtype=int)\n",
    "    confs = np.zeros((df_test.shape[0], 6), dtype=float)\n",
    "    grids = np.zeros(df_test.shape[0], dtype=int)\n",
    "#     correct=np.zeros()\n",
    "\n",
    "    iterations_x = int(grid_size / x_step) # 20\n",
    "    iterations_y = int(grid_size / y_step) # 40\n",
    "\n",
    "    sTime=time.time()\n",
    "    \n",
    "    \n",
    "    gridNum=0\n",
    "    \n",
    "    for i in range(iterations_x):\n",
    "        print(i)\n",
    "        x_min = x_step * i\n",
    "        x_max = x_step * i + x_step\n",
    "        x_min = round(x_min, 4)\n",
    "        x_max = round(x_max, 4)\n",
    "        if x_max == grid_size:\n",
    "            x_max += 0.001\n",
    "\n",
    "        for j in range(iterations_y):\n",
    "            y_min = y_step * j\n",
    "            y_max = y_step * j + y_step\n",
    "            y_min = round(y_min, 4)\n",
    "            y_max = round(y_max, 4)\n",
    "            if y_max == grid_size:\n",
    "                y_max += 0.001\n",
    "\n",
    "            # Applying classifier to one grid cell\n",
    "            pred_labels, pred_confs, row_ids = process_one_cell(df_train, df_test, th, x_min, y_min, x_max, y_max, method=method, gridNum=gridNum, cpuCores=cpuCores)\n",
    "\n",
    "            # Updating predictions\n",
    "                       \n",
    "            preds[row_ids] = pred_labels\n",
    "            confs[row_ids]=pred_confs\n",
    "            grids[row_ids]=gridNum\n",
    "            \n",
    "            \n",
    "            \n",
    "            # serialize the grid results to a \n",
    "            # save one file for each grid             \n",
    "            resultFileName='{:04d}-{}-{}-{}-{}.rst'.format(gridNum, x_min, x_max, y_min, y_max)\n",
    "            resultFilePath=folderPath+resultFileName\n",
    "            predColumns=zip(*pred_labels)\n",
    "            confColumns=zip(*pred_confs)\n",
    "\n",
    "\n",
    "            if len(predColumns[2])!=len(pred_labels):\n",
    "                print 'missing values',gridNum, len(predColumns[0])\n",
    "\n",
    "            def FBeval(p1, p2, p3, real):\n",
    "                return (p1==real)+(p2==real)/2.0+(p3==real)/3.0\n",
    "                \n",
    "                \n",
    "            results=pd.DataFrame({'originalIndex': row_ids,\\\n",
    "                                  'x':df_test.loc[row_ids,'x'].tolist(),\\\n",
    "                                  'y':df_test.loc[row_ids, 'y'].tolist(), \\\n",
    "                                  'accuracy':df_test.loc[row_ids, 'accuracy'].tolist(), \\\n",
    "                                  'pred0':predColumns[0], \\\n",
    "                                  'pred1':predColumns[1],\\\n",
    "                                  'pred2':predColumns[2], \\\n",
    "                                  'pred3':predColumns[3], \\\n",
    "                                  'pred4':predColumns[4],\\\n",
    "                                  'pred5':predColumns[5], \\\n",
    "                                  'conf0': confColumns[0], \\\n",
    "                                  'conf1': confColumns[1],\\\n",
    "                                  'conf2': confColumns[2],\\\n",
    "                                  'conf3': confColumns[3], \\\n",
    "                                  'conf4': confColumns[4],\\\n",
    "                                  'conf5': confColumns[5],\\\n",
    "                                  'real':df_test.loc[row_ids, 'place_id'] if 'place_id' in df_test.columns else [0]*len(row_ids),\\\n",
    "                                  'FBscore': [FBeval(predColumns[0][i], predColumns[1][i], predColumns[2][i], df_test.loc[row_ids[i], 'place_id']) for i in xrange(len(row_ids))]\\\n",
    "                                  if 'place_id' in df_test.columns else [0]*len(row_ids),\\\n",
    "                                  'regionalFBScore': [FBscores[-1]]*len(row_ids) if FBscores else [0]*len(row_ids)})\n",
    "            \n",
    "            results.to_csv(resultFilePath)\n",
    "            # file saving is done\n",
    "            \n",
    "            gridNum+=1\n",
    "            \n",
    "            \n",
    "        print time.time()-sTime\n",
    "        if FBscores:\n",
    "            print sum(FBscores)/len(FBscores)\n",
    "        sTime=time.time()\n",
    "        \n",
    "        \n",
    "    print 'Generating submission files'\n",
    "        # Auxiliary dataframe with the 3 best predictions for each sample\n",
    "    df_aux = pd.DataFrame(preds, dtype=str, columns=['pred0', 'pred1', 'pred2', 'pred3', 'pred4', 'pred5'])\n",
    "    \n",
    "    df_confs = pd.DataFrame(confs, columns=['conf0', 'conf1', 'conf2', 'conf3', 'conf4', 'conf5'])\n",
    "    df_confs = pd.concat([df_aux, df_confs], axis=1)\n",
    "    df_confs['grid']=grids\n",
    "        \n",
    "    if mode=='test':\n",
    "        # Concatenating the 3 predictions for each sample\n",
    "        ds_sub = df_aux.pred0.str.cat([df_aux.pred1, df_aux.pred2], sep=' ')\n",
    "        ds_sub.name = 'place_id'\n",
    "        resultFile=time.strftime('%c')+'-'+method+'-'+note\n",
    "        ds_sub.to_csv(resultFile+'submit.csv', index=True, header=True, index_label='row_id')\n",
    "        df_confs.to_csv(resultFile+'confidence.csv', index=True, index_label='row_id')\n",
    "    elif mode=='valid':\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "df_train = pd.read_csv('../input/train.csv',\n",
    "                       usecols=['row_id', 'x', 'y', 'accuracy', 'time', 'place_id'],\n",
    "                       index_col=0)\n",
    "df_test = pd.read_csv('../input/test.csv',\n",
    "                      usecols=['row_id', 'x', 'y', 'accuracy', 'time'],\n",
    "                      index_col=0)\n",
    "\n",
    "div=int(0.7*len(df_train))\n",
    "\n",
    "df_train.sort_values(by=['time'], inplace=True)\n",
    "df_validation_train=df_train[:div]\n",
    "df_validation_test=df_train[div:]\n",
    "df_validation_test.index=xrange(len(df_validation_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_validation_test.head()\n",
    "# df_validation_train.head()\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train data\n",
      "(29118021, 9)\n",
      "(33946497, 9)\n",
      "Preparing test data\n"
     ]
    }
   ],
   "source": [
    "print('Preparing train data')\n",
    "df_train = prepare_data(df_train)\n",
    "print(df_train.shape)\n",
    "# add data for periodic time that hit the boundary\n",
    "pd.options.mode.chained_assignment = None\n",
    "add_data1 = df_train[df_train.hour < 10]\n",
    "add_data1.hour += 96\n",
    "add_data2 = df_train[df_train.hour > 90]\n",
    "add_data2.hour -= 96\n",
    "df_train = df_train.append(add_data1)\n",
    "df_train = df_train.append(add_data2)\n",
    "\n",
    "print(df_train.shape)\n",
    "print('Preparing test data')\n",
    "df_test = prepare_data(df_test)\n",
    "#########################################################################\n",
    "df_validation_train=prepare_data(df_validation_train)\n",
    "df_validation_test=prepare_data(df_validation_test)\n",
    "\n",
    "add_data1 = df_validation_train[df_validation_train.hour < 10]\n",
    "add_data1.hour += 96\n",
    "add_data2 = df_validation_train[df_validation_train.hour > 90]\n",
    "add_data2.hour -= 96\n",
    "df_validation_train = df_validation_train.append(add_data1)\n",
    "df_validation_train = df_validation_train.append(add_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "region 0: 0.0,0.0 accuracy: 0.757035429103,  fbAccu: 0.575367599556, confidence: 0.687734476113:\n",
      "region 1: 0.0,0.25 accuracy: 0.71720505618,  fbAccu: 0.533719569288, confidence: 0.682132810904:\n",
      "region 2: 0.0,0.5 accuracy: 0.708570362772,  fbAccu: 0.538888370792, confidence: 0.668949301425:\n",
      "region 3: 0.0,0.75 accuracy: 0.714851485149,  fbAccu: 0.544105610561, confidence: 0.696884298929:\n",
      "region 4: 0.0,1.0 accuracy: 0.720268638696,  fbAccu: 0.560141865379, confidence: 0.687532128985:\n",
      "region 5: 0.0,1.25 accuracy: 0.75618165698,  fbAccu: 0.56779299248, confidence: 0.666878964181:\n"
     ]
    }
   ],
   "source": [
    "# Solving classification problems inside each grid cell\n",
    "th = 5  # Keeping place_ids with more than th samples.\n",
    "mode='valid'\n",
    "method='rf'\n",
    "note=''\n",
    "\n",
    "cpuCores=-1\n",
    "\n",
    "\n",
    "accuracies=[]\n",
    "FBscores=[]\n",
    "\n",
    "if mode=='test':\n",
    "    process_grid(df_train, df_test, th, method=method, note=note, mode=mode, cpuCores=cpuCores)\n",
    "if mode=='valid':\n",
    "    process_grid(df_validation_train, df_validation_test, th, method=method, note=note, mode=mode, cpuCores=cpuCores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confs=pd.read_csv('Wed Jun 29 12:03:11 2016-knn-confidence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5990068280571074"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7493604155360881"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=pd.read_csv('xgb-Wed Jun 29 23:34:00 2016//0000-0.0-0.5-0.0-0.25.rst')\n",
    "th=0.3\n",
    "l=len(r)\n",
    "a=len(r[(r.conf0>th)])\n",
    "b=len(r[(r.conf0>th) & (r.pred0 != r.real)])\n",
    "1.0*(a-b)/a\n",
    "1.0*a/l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### FBscores\n",
    "confs.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
