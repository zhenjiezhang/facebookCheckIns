{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Feature engineering...\n",
      "    Computing some features from x and y ...\n",
      "    Creating datetime features ...\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "__author__ = 'Sandro Vega Pons : https://www.kaggle.com/svpons'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def prepare_data(df_train, df_test, n_cell_x, n_cell_y):\n",
    "    \"\"\"\n",
    "    Some feature engineering (mainly with the time feature) + normalization \n",
    "    of all features (substracting the mean and dividing by std) +  \n",
    "    computation of a grid (size = n_cell_x * n_cell_y), which is included\n",
    "    as a new column (grid_cell) in the dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------    \n",
    "    df_train: pandas DataFrame\n",
    "              Training data\n",
    "    df_test : pandas DataFrame\n",
    "              Test data\n",
    "    n_cell_x: int\n",
    "              Number of grid cells on the x axis\n",
    "    n_cell_y: int\n",
    "              Number of grid cells on the y axis\n",
    "    \n",
    "    Returns:\n",
    "    -------    \n",
    "    df_train, df_test: pandas DataFrame\n",
    "                       Modified training and test datasets.\n",
    "    \"\"\"  \n",
    "    print('Feature engineering...')\n",
    "    print('    Computing some features from x and y ...')\n",
    "    ##x, y, and accuracy remain the same\n",
    "        ##New feature x/y\n",
    "    eps = 0.00001  #required to avoid some divisions by zero.\n",
    "    df_train['x_d_y'] = df_train.x.values / (df_train.y.values + eps) \n",
    "    df_test['x_d_y'] = df_test.x.values / (df_test.y.values + eps) \n",
    "        ##New feature x*y\n",
    "    df_train['x_t_y'] = df_train.x.values * df_train.y.values  \n",
    "    df_test['x_t_y'] = df_test.x.values * df_test.y.values\n",
    "    \n",
    "    print('    Creating datetime features ...')\n",
    "    ##time related features (assuming the time = minutes)\n",
    "    initial_date = np.datetime64('2014-01-01T01:01',   #Arbitrary decision\n",
    "                                 dtype='datetime64[m]') \n",
    "        #working on df_train  \n",
    "    d_times = pd.DatetimeIndex(initial_date + np.timedelta64(int(mn), 'm') \n",
    "                               for mn in df_train.time.values)    \n",
    "    df_train['hour'] = d_times.hour\n",
    "    df_train['weekday'] = d_times.weekday\n",
    "    df_train['day'] = d_times.day\n",
    "    df_train['month'] = d_times.month\n",
    "    df_train['year'] = d_times.year\n",
    "    df_train = df_train.drop(['time'], axis=1)\n",
    "        #working on df_test    \n",
    "    d_times = pd.DatetimeIndex(initial_date + np.timedelta64(int(mn), 'm') \n",
    "                               for mn in df_test.time.values)    \n",
    "    df_test['hour'] = d_times.hour\n",
    "    df_test['weekday'] = d_times.weekday\n",
    "    df_test['day'] = d_times.day\n",
    "    df_test['month'] = d_times.month\n",
    "    df_test['year'] = d_times.year\n",
    "    df_test = df_test.drop(['time'], axis=1)\n",
    "    \n",
    "    print('Computing the grid ...')\n",
    "    #Creating a new colum with grid_cell id  (there will be \n",
    "    #n = (n_cell_x * n_cell_y) cells enumerated from 0 to n-1)\n",
    "    size_x = 10. / n_cell_x\n",
    "    size_y = 10. / n_cell_y\n",
    "        #df_train\n",
    "    xs = np.where(df_train.x.values < eps, 0, df_train.x.values - eps)\n",
    "    ys = np.where(df_train.y.values < eps, 0, df_train.y.values - eps)\n",
    "    pos_x = (xs / size_x).astype(np.int)\n",
    "    pos_y = (ys / size_y).astype(np.int)\n",
    "    df_train['grid_cell'] = pos_y * n_cell_x + pos_x\n",
    "            #df_test\n",
    "    xs = np.where(df_test.x.values < eps, 0, df_test.x.values - eps)\n",
    "    ys = np.where(df_test.y.values < eps, 0, df_test.y.values - eps)\n",
    "    pos_x = (xs / size_x).astype(np.int)\n",
    "    pos_y = (ys / size_y).astype(np.int)\n",
    "    df_test['grid_cell'] = pos_y * n_cell_x + pos_x \n",
    "    \n",
    "    ##Normalization\n",
    "    print('Normalizing the data: (X - mean(X)) / std(X) ...')\n",
    "    cols = ['x', 'y', 'accuracy', 'x_d_y', 'x_t_y', 'hour', \n",
    "            'weekday', 'day', 'month', 'year']\n",
    "    for cl in cols:\n",
    "        ave = df_train[cl].mean()\n",
    "        std = df_train[cl].std()\n",
    "        df_train[cl] = (df_train[cl].values - ave ) / std\n",
    "        df_test[cl] = (df_test[cl].values - ave ) / std\n",
    "        \n",
    "    #Returning the modified dataframes\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_one_cell(df_train, df_test, grid_id, th):\n",
    "    \"\"\"\n",
    "    Does all the processing inside a single grid cell: Computes the training\n",
    "    and test sets inside the cell. Fits a classifier to the training data\n",
    "    and predicts on the test data. Selects the top 3 predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------    \n",
    "    df_train: pandas DataFrame\n",
    "              Training set\n",
    "    df_test: pandas DataFrame\n",
    "             Test set\n",
    "    grid_id: int\n",
    "             The id of the grid to be analyzed\n",
    "    th: int\n",
    "       Threshold for place_id. Only samples with place_id with at least th\n",
    "       occurrences are kept in the training set.\n",
    "    \n",
    "    Return:\n",
    "    ------    \n",
    "    pred_labels: numpy ndarray\n",
    "                 Array with the prediction of the top 3 labels for each sample\n",
    "    row_ids: IDs of the samples in the submission dataframe \n",
    "    \"\"\"   \n",
    "    #Working on df_train\n",
    "    print \"processing one cell\"\n",
    "    df_cell_train = df_train[df_train['grid_cell']==0]\n",
    "    print \"selected\"\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = place_counts[df_cell_train.place_id.values] >= th\n",
    "    df_cell_train = df_cell_train.loc[mask.values]\n",
    "    print \"working on test\"\n",
    "\n",
    "    #Working on df_test\n",
    "    df_cell_test = df_test[df_test.grid_cell == grid_id]\n",
    "    row_ids = df_cell_test.index\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id', 'grid_cell'], axis = 1).values\n",
    "\n",
    "    #Training Classifier\n",
    "    print \"training classifier\"\n",
    "    clf = SGDClassifier(loss='modified_huber', n_iter=1, random_state=0, n_jobs=-1)  \n",
    "    clf.fit(X, y)\n",
    "    X_test = df_cell_test.drop(['grid_cell'], axis = 1).values\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3])    \n",
    "    return pred_labels, row_ids\n",
    "\n",
    "def process_grid(df_train, df_test, df_sub, th, n_cells):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells and aggregates the results of individual cells\n",
    "    \"\"\"    \n",
    "    for g_id in range(n_cells):\n",
    "        if g_id % 10 == 0:\n",
    "            print('iteration: %s' %(g_id))\n",
    "        \n",
    "        #Applying classifier to one grid cell\n",
    "        pred_labels, row_ids = process_one_cell(df_train, df_test, g_id, th)\n",
    "        #Converting the prediction to the submission format\n",
    "        str_labels = np.apply_along_axis(lambda x: ' '.join(x.astype(str)), \n",
    "                                         1, pred_labels)\n",
    "        #Updating submission file\n",
    "        df_sub.loc[row_ids] = str_labels.reshape(-1,1)\n",
    "        \n",
    "    return df_sub       \n",
    "                 \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print('Loading data ...')\n",
    "    df_train = pd.read_csv('../input/train.csv', dtype={'x':np.float32, \n",
    "                                               'y':np.float32, \n",
    "                                               'accuracy':np.int16,\n",
    "                                               'time':np.int,\n",
    "                                               'place_id':np.int}, \n",
    "                                               index_col = 0)\n",
    "    df_test = pd.read_csv('../input/test.csv', dtype={'x':np.float32,\n",
    "                                              'y':np.float32, \n",
    "                                              'accuracy':np.int16,\n",
    "                                              'time':np.int,\n",
    "                                              'place_id':np.int}, \n",
    "                                              index_col = 0)\n",
    "    df_sub = pd.read_csv('../input/sample_submission.csv', index_col = 0) \n",
    "    \n",
    "#     df_train=df_train[:10]\n",
    "#     df_test=df_test[:10]\n",
    "#     df_sub=df_sub[:10]\n",
    "    \n",
    "    #Defining the size of the grid\n",
    "    n_cell_x = 10\n",
    "    n_cell_y = 10 \n",
    "    df_train, df_test = prepare_data(df_train, df_test, n_cell_x, n_cell_y)\n",
    "    \n",
    "    #Solving classification problems inside each grid cell\n",
    "    th = 5 #Threshold on place_id inside each cell. Only place_ids with at \n",
    "            #least th occurrences inside each grid_cell are considered. This\n",
    "            #is to avoid classes with very few samples and speed-up the \n",
    "            #computation.\n",
    "    \n",
    "    df_submission  = process_grid(df_train, df_test, df_sub, th, \n",
    "                                  n_cell_x * n_cell_y)                                 \n",
    "    #creating the submission\n",
    "    print('Generating submission file ...')\n",
    "    df_submission.to_csv(\"sub.csv\", index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
